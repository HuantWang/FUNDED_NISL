-----label-----
1
-----code-----
void
xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
			  dma_addr_t dev_addr, struct dma_attrs *attrs)
{
	int order = get_order(size);
	phys_addr_t phys;
	u64 dma_mask = DMA_BIT_MASK(32);

	if (hwdev && hwdev->coherent_dma_mask)
		dma_mask = hwdev->coherent_dma_mask;

	/* do not use virt_to_phys because on ARM it doesn't return you the
	 * physical address */
	phys = xen_bus_to_phys(dev_addr);

	/* Convert the size to actually allocated. */
	size = 1UL << (order + XEN_PAGE_SHIFT);

	if (((dev_addr + size - 1 <= dma_mask)) ||
	    range_straddles_page_boundary(phys, size))
		xen_destroy_contiguous_region(phys, order);

	xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs);
}
-----children-----
1,2
1,3
1,4
3,4
3,5
3,6
3,7
3,8
3,9
5,6
5,7
6,7
8,9
8,10
11,12
11,13
12,13
14,15
16,17
16,18
18,19
18,20
21,22
21,23
22,23
24,25
26,27
26,28
27,28
29,30
29,31
32,33
32,34
32,35
32,36
32,37
32,38
32,39
32,40
33,34
34,35
34,36
36,37
36,38
38,39
39,40
39,41
40,41
42,43
44,45
45,46
45,47
46,47
48,49
50,51
51,52
51,53
52,53
54,55
54,56
56,57
57,58
57,59
58,59
61,62
61,63
62,63
62,64
63,64
65,66
65,67
66,67
69,70
70,71
70,72
71,72
73,74
73,75
74,75
77,78
78,79
78,80
79,80
81,82
81,83
82,83
84,85
86,87
87,88
87,89
88,89
90,91
90,92
92,93
93,94
93,95
94,95
96,97
98,99
98,100
99,100
99,101
100,101
101,102
102,103
102,104
103,104
103,105
104,105
104,106
105,106
107,108
110,111
112,113
112,114
112,115
113,114
115,116
117,118
119,120
120,121
120,122
120,123
121,122
123,124
125,126
127,128
128,129
128,130
128,131
128,132
128,133
128,134
129,130
131,132
133,134
135,136
137,138
137,139
138,139
138,140
139,140
142,143
144,145
-----nextToken-----
2,4,7,9,10,13,15,17,19,20,23,25,28,30,31,35,37,41,43,47,49,53,55,59,60,64,67,68,72,75,76,80,83,85,89,91,95,97,106,108,109,111,114,116,118,122,124,126,130,132,134,136,140,141,143,145
-----computeFrom-----
62,63
62,64
70,71
70,72
78,79
78,80
87,88
87,89
90,91
90,92
93,94
93,95
99,100
99,101
102,103
102,104
103,104
103,105
104,105
104,106
-----guardedBy-----
68,76
67,75
116,124
-----guardedByNegation-----
-----lastLexicalUse-----
-----jump-----
-----attribute-----
FunctionDefinition;SimpleDeclSpecifier;FunctionDeclarator;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;ParameterDeclaration;NamedTypeSpecifier;Name;Declarator;Name;ParameterDeclaration;SimpleDeclSpecifier;Declarator;Pointer;Name;ParameterDeclaration;NamedTypeSpecifier;Name;Declarator;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;SimpleDeclSpecifier;Declarator;Name;EqualsInitializer;FunctionCallExpression;IdExpression;Name;IdExpression;Name;DeclarationStatement;SimpleDeclaration;NamedTypeSpecifier;Name;Declarator;Name;DeclarationStatement;SimpleDeclaration;NamedTypeSpecifier;Name;Declarator;Name;EqualsInitializer;FunctionCallExpression;IdExpression;Name;LiteralExpression;IfStatement;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;BinaryExpression;LiteralExpression;UnaryExpression;BinaryExpression;IdExpression;Name;IdExpression;Name;IfStatement;BinaryExpression;UnaryExpression;UnaryExpression;BinaryExpression;BinaryExpression;BinaryExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;IdExpression;Name;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;IdExpression;Name;CastExpression;TypeId;NamedTypeSpecifier;Name;Declarator;IdExpression;Name;IdExpression;Name;
-----ast_node-----
voidxen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,			  dma_addr_t dev_addr, struct dma_attrs *attrs){	int order = get_order(size);	phys_addr_t phys;	u64 dma_mask = DMA_BIT_MASK(32);	if (hwdev && hwdev->coherent_dma_mask)		dma_mask = hwdev->coherent_dma_mask;	/* do not use virt_to_phys because on ARM it doesn't return you the	 * physical address */	phys = xen_bus_to_phys(dev_addr);	/* Convert the size to actually allocated. */	size = 1UL << (order + XEN_PAGE_SHIFT);	if (((dev_addr + size - 1 <= dma_mask)) ||	    range_straddles_page_boundary(phys, size))		xen_destroy_contiguous_region(phys, order);	xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs);}
void
xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,			  dma_addr_t dev_addr, struct dma_attrs *attrs)
xen_swiotlb_free_coherent
struct device *hwdev
struct device
device
*hwdev
*
hwdev
size_t size
size_t
size_t
size
size
void *vaddr
void
*vaddr
*
vaddr
dma_addr_t dev_addr
dma_addr_t
dma_addr_t
dev_addr
dev_addr
struct dma_attrs *attrs
struct dma_attrs
dma_attrs
*attrs
*
attrs
{	int order = get_order(size);	phys_addr_t phys;	u64 dma_mask = DMA_BIT_MASK(32);	if (hwdev && hwdev->coherent_dma_mask)		dma_mask = hwdev->coherent_dma_mask;	/* do not use virt_to_phys because on ARM it doesn't return you the	 * physical address */	phys = xen_bus_to_phys(dev_addr);	/* Convert the size to actually allocated. */	size = 1UL << (order + XEN_PAGE_SHIFT);	if (((dev_addr + size - 1 <= dma_mask)) ||	    range_straddles_page_boundary(phys, size))		xen_destroy_contiguous_region(phys, order);	xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs);}
int order = get_order(size);
int order = get_order(size);
int
order = get_order(size)
order
= get_order(size)
get_order(size)
get_order
get_order
size
size
phys_addr_t phys;
phys_addr_t phys;
phys_addr_t
phys_addr_t
phys
phys
u64 dma_mask = DMA_BIT_MASK(32);
u64 dma_mask = DMA_BIT_MASK(32);
u64
u64
dma_mask = DMA_BIT_MASK(32)
dma_mask
= DMA_BIT_MASK(32)
DMA_BIT_MASK(32)
DMA_BIT_MASK
DMA_BIT_MASK
32
if (hwdev && hwdev->coherent_dma_mask)		dma_mask = hwdev->coherent_dma_mask;
hwdev && hwdev->coherent_dma_mask
hwdev
hwdev
hwdev->coherent_dma_mask
hwdev
hwdev
coherent_dma_mask
dma_mask = hwdev->coherent_dma_mask;
dma_mask = hwdev->coherent_dma_mask
dma_mask
dma_mask
hwdev->coherent_dma_mask
hwdev
hwdev
coherent_dma_mask
phys = xen_bus_to_phys(dev_addr);
phys = xen_bus_to_phys(dev_addr)
phys
phys
xen_bus_to_phys(dev_addr)
xen_bus_to_phys
xen_bus_to_phys
dev_addr
dev_addr
size = 1UL << (order + XEN_PAGE_SHIFT);
size = 1UL << (order + XEN_PAGE_SHIFT)
size
size
1UL << (order + XEN_PAGE_SHIFT)
1UL
(order + XEN_PAGE_SHIFT)
order + XEN_PAGE_SHIFT
order
order
XEN_PAGE_SHIFT
XEN_PAGE_SHIFT
if (((dev_addr + size - 1 <= dma_mask)) ||	    range_straddles_page_boundary(phys, size))		xen_destroy_contiguous_region(phys, order);
((dev_addr + size - 1 <= dma_mask)) ||	    range_straddles_page_boundary(phys, size)
((dev_addr + size - 1 <= dma_mask))
(dev_addr + size - 1 <= dma_mask)
dev_addr + size - 1 <= dma_mask
dev_addr + size - 1
dev_addr + size
dev_addr
dev_addr
size
size
1
dma_mask
dma_mask
range_straddles_page_boundary(phys, size)
range_straddles_page_boundary
range_straddles_page_boundary
phys
phys
size
size
xen_destroy_contiguous_region(phys, order);
xen_destroy_contiguous_region(phys, order)
xen_destroy_contiguous_region
xen_destroy_contiguous_region
phys
phys
order
order
xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs);
xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs)
xen_free_coherent_pages
xen_free_coherent_pages
hwdev
hwdev
size
size
vaddr
vaddr
(dma_addr_t)phys
dma_addr_t
dma_addr_t
dma_addr_t

phys
phys
attrs
attrs
-----joern-----
(11,45,0)
(56,45,0)
(36,50,0)
(13,28,0)
(37,30,0)
(11,3,0)
(48,4,0)
(45,26,0)
(48,3,0)
(30,10,0)
(28,22,0)
(60,48,0)
(62,19,0)
(20,11,0)
(51,20,0)
(0,47,0)
(31,30,0)
(7,26,0)
(39,52,0)
(5,11,0)
(19,6,0)
(11,6,0)
(4,48,0)
(38,1,0)
(24,40,0)
(55,62,0)
(1,50,0)
(27,47,0)
(42,6,0)
(44,6,0)
(4,52,0)
(17,27,0)
(20,32,0)
(48,1,0)
(22,1,0)
(27,6,0)
(52,10,0)
(32,14,0)
(20,3,0)
(24,8,0)
(32,20,0)
(25,27,0)
(48,11,0)
(50,14,0)
(52,32,0)
(25,1,0)
(10,30,0)
(22,12,0)
(16,19,0)
(28,3,0)
(22,28,0)
(59,6,0)
(2,48,0)
(41,25,0)
(50,1,0)
(26,45,0)
(8,24,0)
(29,24,0)
(46,20,0)
(53,28,0)
(47,3,0)
(32,52,0)
(21,32,0)
(28,11,0)
(8,40,0)
(52,4,0)
(30,40,0)
(54,25,0)
(33,28,0)
(15,8,0)
(49,10,0)
(19,62,0)
(18,6,0)
(43,6,0)
(52,19,0)
(47,27,0)
(28,6,0)
(28,58,0)
(23,28,0)
(34,24,0)
(45,11,0)
(28,61,0)
(28,40,0)
(26,27,0)
(35,22,0)
(12,22,0)
(1,6,0)
(9,26,0)
(45,26,1)
(28,58,1)
(24,40,1)
(1,50,1)
(25,1,1)
(33,22,1)
(23,25,1)
(20,11,1)
(41,4,1)
(38,10,1)
(24,29,1)
(2,60,1)
(50,14,1)
(50,36,1)
(62,55,1)
(20,3,1)
(5,1,1)
(52,32,1)
(26,27,1)
(9,7,1)
(27,47,1)
(46,21,1)
(39,32,1)
(56,5,1)
(48,11,1)
(8,40,1)
(28,33,1)
(25,27,1)
(16,27,1)
(31,49,1)
(60,52,1)
(48,1,1)
(22,35,1)
(4,52,1)
(49,8,1)
(47,0,1)
(34,15,1)
(15,19,1)
(28,11,1)
(28,22,1)
(32,20,1)
(52,19,1)
(35,53,1)
(30,37,1)
(38,8,1)
(55,16,1)
(48,3,1)
(0,17,1)
(20,51,1)
(25,54,1)
(11,45,1)
(37,31,1)
(57,28,1)
(52,39,1)
(47,3,1)
(13,23,1)
(36,38,1)
(21,11,1)
(52,10,1)
(32,14,1)
(11,3,1)
(28,61,1)
(4,48,1)
(51,46,1)
(48,2,1)
(22,1,1)
(8,15,1)
(28,40,1)
(23,4,1)
(10,30,1)
(7,56,1)
(26,9,1)
(22,12,1)
(28,3,1)
(29,34,1)
(19,62,1)
(53,13,1)
(30,40,1)
(54,41,1)
(8,24,1)
(27,47,2)
(32,20,2)
(52,10,2)
(22,12,2)
(4,48,2)
(8,40,2)
(11,3,2)
(28,22,2)
(49,8,2)
(29,15,2)
(1,50,2)
(54,4,2)
(52,19,2)
(45,26,2)
(24,40,2)
(25,27,2)
(25,1,2)
(26,27,2)
(25,4,2)
(28,3,2)
(47,3,2)
(34,15,2)
(10,8,2)
(48,1,2)
(30,8,2)
(28,58,2)
(52,32,2)
(2,52,2)
(50,14,2)
(30,40,2)
(20,3,2)
(48,52,2)
(24,15,2)
(10,30,2)
(31,8,2)
(28,61,2)
(22,1,2)
(41,4,2)
(20,11,2)
(60,52,2)
(28,40,2)
(19,62,2)
(8,24,2)
(4,52,2)
(37,8,2)
(28,11,2)
(48,3,2)
(32,14,2)
(11,45,2)
(48,11,2)
-----------------------------------
(0,size)
(1,phys = xen_bus_to_phys(dev_addr)
(2,size)
(3,size_t size)
(4,((dev_addr + size - 1 <= dma_mask)
(5,size)
(6,)
(7,order)
(8,hwdev && hwdev->coherent_dma_mask)
(9,XEN_PAGE_SHIFT)
(10,dma_mask = hwdev->coherent_dma_mask)
(11,size = 1UL << (order + XEN_PAGE_SHIFT)
(12,dma_addr_t)
(13,size)
(14,dma_addr_t dev_addr)
(15,hwdev)
(16,dma_mask)
(17,order)
(18,order)
(19,dma_mask = DMA_BIT_MASK(32)
(20,size - 1)
(21,dev_addr)
(22,(dma_addr_t)
(23,hwdev)
(24,hwdev->coherent_dma_mask)
(25,xen_destroy_contiguous_region(phys, order)
(26,order + XEN_PAGE_SHIFT)
(27,order = get_order(size)
(28,xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)
(29,coherent_dma_mask)
(30,hwdev->coherent_dma_mask)
(31,hwdev)
(32,dev_addr + size - 1)
(33,attrs)
(34,hwdev)
(35,phys)
(36,dev_addr)
(37,coherent_dma_mask)
(38,phys)
(39,dma_mask)
(40,struct device *hwdev)
(41,phys)
(42,phys)
(43,dma_mask)
(44,if (hwdev && hwdev->coherent_dma_mask)
(45,1UL << (order + XEN_PAGE_SHIFT)
(46,size)
(47,get_order(size)
(48,range_straddles_page_boundary(phys, size)
(49,dma_mask)
(50,xen_bus_to_phys(dev_addr)
(51,1)
(52,dev_addr + size - 1 <= dma_mask)
(53,vaddr)
(54,order)
(55,32)
(56,1UL)
(57,RET)
(58,struct dma_attrs *attrs)
(59,if (((dev_addr + size - 1 <= dma_mask)
(60,phys)
(61,void *vaddr)
(62,DMA_BIT_MASK(32)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-----label-----
0
-----code-----
static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,
				   struct vmcs12 *vmcs12)
{
	struct kvm_segment seg;

	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)
		vcpu->arch.efer = vmcs12->host_ia32_efer;
	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)
		vcpu->arch.efer |= (EFER_LMA | EFER_LME);
	else
		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);
	vmx_set_efer(vcpu, vcpu->arch.efer);

	kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);
	kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);
	vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);
	/*
	 * Note that calling vmx_set_cr0 is important, even if cr0 hasn't
	 * actually changed, because it depends on the current state of
	 * fpu_active (which may have changed).
	 * Note that vmx_set_cr0 refers to efer set above.
	 */
	vmx_set_cr0(vcpu, vmcs12->host_cr0);
	/*
	 * If we did fpu_activate()/fpu_deactivate() during L2's run, we need
	 * to apply the same changes to L1's vmcs. We just set cr0 correctly,
	 * but we also need to update cr0_guest_host_mask and exception_bitmap.
	 */
	update_exception_bitmap(vcpu);
	vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);
	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);

	/*
	 * Note that CR4_GUEST_HOST_MASK is already set in the original vmcs01
	 * (KVM doesn't change it)- no reason to call set_cr4_guest_host_mask();
	 */
	vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);
	vmx_set_cr4(vcpu, vmcs12->host_cr4);

	nested_ept_uninit_mmu_context(vcpu);

	kvm_set_cr3(vcpu, vmcs12->host_cr3);
	kvm_mmu_reset_context(vcpu);

	if (!enable_ept)
		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;

	if (enable_vpid) {
		/*
		 * Trivially support vpid by letting L2s share their parent
		 * L1's vpid. TODO: move to a more elaborate solution, giving
		 * each L2 its own vpid and exposing the vpid feature to L1.
		 */
		vmx_flush_tlb(vcpu);
	}


	vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);
	vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);
	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);
	vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);
	vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);
	vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);
	vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);

	/* If not VM_EXIT_CLEAR_BNDCFGS, the L2 value propagates to L1.  */
	if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)
		vmcs_write64(GUEST_BNDCFGS, 0);

	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {
		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);
		vcpu->arch.pat = vmcs12->host_ia32_pat;
	}
	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)
		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,
			vmcs12->host_ia32_perf_global_ctrl);

	/* Set L1 segment info according to Intel SDM
	    27.5.2 Loading Host Segment and Descriptor-Table Registers */
	seg = (struct kvm_segment) {
		.base = 0,
		.limit = 0xFFFFFFFF,
		.selector = vmcs12->host_cs_selector,
		.type = 11,
		.present = 1,
		.s = 1,
		.g = 1
	};
	if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)
		seg.l = 1;
	else
		seg.db = 1;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);
	seg = (struct kvm_segment) {
		.base = 0,
		.limit = 0xFFFFFFFF,
		.type = 3,
		.present = 1,
		.s = 1,
		.db = 1,
		.g = 1
	};
	seg.selector = vmcs12->host_ds_selector;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);
	seg.selector = vmcs12->host_es_selector;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);
	seg.selector = vmcs12->host_ss_selector;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);
	seg.selector = vmcs12->host_fs_selector;
	seg.base = vmcs12->host_fs_base;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);
	seg.selector = vmcs12->host_gs_selector;
	seg.base = vmcs12->host_gs_base;
	vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);
	seg = (struct kvm_segment) {
		.base = vmcs12->host_tr_base,
		.limit = 0x67,
		.selector = vmcs12->host_tr_selector,
		.type = 11,
		.present = 1
	};
	vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);

	kvm_set_dr(vcpu, 7, 0x400);
	vmcs_write64(GUEST_IA32_DEBUGCTL, 0);

	if (cpu_has_vmx_msr_bitmap())
		vmx_set_msr_bitmap(vcpu);

	if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,
				vmcs12->vm_exit_msr_load_count))
		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);
}
-----children-----
1,2
1,3
1,4
3,4
3,5
3,6
5,6
5,7
6,7
8,9
8,10
11,12
11,13
12,13
14,15
14,16
17,18
17,19
17,20
17,21
17,22
17,23
17,24
17,25
17,26
17,27
17,28
17,29
17,30
17,31
17,32
17,33
17,34
17,35
17,36
17,37
17,38
17,39
17,40
17,41
17,42
17,43
17,44
17,45
17,46
17,47
17,48
17,49
17,50
17,51
17,52
17,53
17,54
17,55
17,56
17,57
17,58
17,59
17,60
17,61
17,62
17,63
17,64
17,65
17,66
18,19
19,20
19,21
20,21
22,23
24,25
24,26
24,27
25,26
25,27
26,27
26,28
27,28
30,31
32,33
33,34
33,35
34,35
34,36
35,36
35,37
36,37
40,41
40,42
41,42
44,45
44,46
44,47
45,46
45,47
46,47
46,48
47,48
50,51
52,53
53,54
53,55
54,55
54,56
55,56
55,57
56,57
60,61
61,62
61,63
62,63
64,65
66,67
67,68
67,69
68,69
68,70
69,70
69,71
70,71
74,75
75,76
76,77
76,78
77,78
79,80
81,82
82,83
82,84
82,85
83,84
85,86
87,88
87,89
88,89
88,90
89,90
93,94
94,95
94,96
94,97
94,98
95,96
97,98
99,100
101,102
101,103
102,103
105,106
106,107
106,108
106,109
106,110
107,108
109,110
111,112
113,114
113,115
114,115
117,118
118,119
118,120
118,121
119,120
121,122
123,124
125,126
126,127
126,128
126,129
127,128
129,130
131,132
131,133
132,133
135,136
136,137
136,138
137,138
139,140
141,142
142,143
142,144
143,144
143,145
144,145
144,146
145,146
149,150
150,151
150,152
150,153
151,152
151,153
152,153
155,156
158,159
159,160
159,161
159,162
160,161
162,163
164,165
165,166
165,167
166,167
166,168
167,168
171,172
172,173
172,174
173,174
173,175
174,175
174,176
175,176
179,180
180,181
180,182
181,182
183,184
185,186
186,187
186,188
186,189
187,188
189,190
191,192
191,193
192,193
195,196
196,197
196,198
197,198
199,200
201,202
202,203
202,204
202,205
203,204
205,206
207,208
207,209
208,209
211,212
212,213
212,214
213,214
215,216
217,218
217,219
218,219
219,220
221,222
222,223
222,224
223,224
223,225
224,225
224,226
225,226
225,227
226,227
231,232
233,234
233,235
234,235
236,237
237,238
238,239
238,240
239,240
241,242
243,244
244,245
244,246
244,247
245,246
247,248
249,250
249,251
250,251
253,254
254,255
254,256
254,257
255,256
257,258
259,260
259,261
260,261
263,264
264,265
264,266
264,267
265,266
267,268
269,270
269,271
270,271
273,274
274,275
274,276
274,277
275,276
277,278
279,280
279,281
280,281
283,284
284,285
284,286
284,287
285,286
287,288
289,290
289,291
290,291
293,294
294,295
294,296
294,297
295,296
297,298
300,301
301,302
301,303
301,304
302,303
304,305
307,308
307,309
308,309
308,310
309,310
309,311
310,311
313,314
315,316
316,317
316,318
316,319
317,318
319,320
322,323
322,324
323,324
323,325
324,325
324,326
325,326
328,329
330,331
330,332
331,332
332,333
332,334
332,335
333,334
335,336
337,338
337,339
338,339
341,342
342,343
342,344
343,344
343,345
344,345
344,346
345,346
349,350
349,351
350,351
353,354
353,355
354,355
354,356
355,356
355,357
356,357
359,360
361,362
362,363
362,364
362,365
363,364
365,366
367,368
367,369
368,369
371,372
372,373
372,374
372,375
373,374
373,375
374,375
374,376
375,376
378,379
380,381
381,382
381,383
382,383
382,384
383,384
387,388
388,389
388,390
389,390
389,391
390,391
394,395
395,396
395,397
395,398
395,399
396,397
398,399
400,401
401,402
403,404
405,406
406,407
407,408
407,409
408,409
408,410
409,410
412,413
412,414
413,414
416,417
417,418
417,419
417,420
417,421
418,419
420,421
422,423
423,424
425,426
427,428
428,429
428,430
429,430
429,431
430,431
433,434
433,435
434,435
437,438
438,439
438,440
438,441
438,442
439,440
441,442
443,444
444,445
446,447
448,449
449,450
449,451
450,451
450,452
451,452
454,455
454,456
455,456
458,459
459,460
459,461
459,462
459,463
460,461
462,463
464,465
465,466
467,468
469,470
470,471
470,472
471,472
471,473
472,473
475,476
475,477
476,477
479,480
480,481
480,482
481,482
481,483
482,483
485,486
485,487
486,487
489,490
490,491
490,492
490,493
490,494
491,492
493,494
495,496
496,497
498,499
500,501
501,502
501,503
502,503
502,504
503,504
506,507
506,508
507,508
510,511
511,512
511,513
512,513
512,514
513,514
516,517
516,518
517,518
520,521
521,522
521,523
521,524
521,525
522,523
524,525
526,527
527,528
529,530
531,532
532,533
533,534
533,535
533,536
533,537
534,535
536,537
538,539
539,540
541,542
543,544
544,545
544,546
544,547
544,548
545,546
547,548
551,552
552,553
552,554
552,555
553,554
555,556
558,559
558,560
559,560
560,561
562,563
563,564
563,565
564,565
566,567
568,569
568,570
569,570
569,571
569,572
569,573
570,571
572,573
574,575
574,576
575,576
578,579
578,580
579,580
582,583
583,584
583,585
583,586
584,585
586,587
588,589
-----nextToken-----
2,4,7,9,10,13,15,16,21,23,28,29,31,37,38,39,42,43,48,49,51,57,58,59,63,65,71,72,73,78,80,84,86,90,91,92,96,98,100,103,104,108,110,112,115,116,120,122,124,128,130,133,134,138,140,146,147,148,153,154,156,157,161,163,168,169,170,176,177,178,182,184,188,190,193,194,198,200,204,206,209,210,214,216,220,227,228,229,230,232,235,240,242,246,248,251,252,256,258,261,262,266,268,271,272,276,278,281,282,286,288,291,292,296,298,299,303,305,306,311,312,314,318,320,321,326,327,329,334,336,339,340,346,347,348,351,352,357,358,360,364,366,369,370,376,377,379,384,385,386,391,392,393,397,399,402,404,410,411,414,415,419,421,424,426,431,432,435,436,440,442,445,447,452,453,456,457,461,463,466,468,473,474,477,478,483,484,487,488,492,494,497,499,504,505,508,509,514,515,518,519,523,525,528,530,535,537,540,542,546,548,549,550,554,556,557,561,565,567,571,573,576,577,580,581,585,587,589
-----computeFrom-----
25,26
25,27
33,34
33,35
45,46
45,47
53,54
53,55
61,62
61,63
67,68
67,69
76,77
76,78
142,143
142,144
172,173
172,174
222,223
222,224
308,309
308,310
323,324
323,325
342,343
342,344
354,355
354,356
373,374
373,375
381,382
381,383
388,389
388,390
407,408
407,409
428,429
428,430
449,450
449,451
470,471
470,472
480,481
480,482
501,502
501,503
511,512
511,513
-----guardedBy-----
28,42
326,351
357,369
-----guardedByNegation-----
28,48
29,49
-----lastLexicalUse-----
28,48
-----jump-----
28,48
-----attribute-----
FunctionDefinition;SimpleDeclSpecifier;FunctionDeclarator;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Name;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;FieldReference;IdExpression;Name;Name;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;UnaryExpression;BinaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;UnaryExpression;UnaryExpression;BinaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;FieldReference;IdExpression;Name;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;UnaryExpression;ConditionalExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;LiteralExpression;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;UnaryExpression;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IfStatement;UnaryExpression;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;FieldReference;IdExpression;Name;Name;Name;Name;IdExpression;Name;IfStatement;IdExpression;Name;CompoundStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;CompoundStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;FieldReference;FieldReference;IdExpression;Name;Name;Name;FieldReference;IdExpression;Name;Name;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;ProblemStatement;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;LiteralExpression;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;LiteralExpression;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ProblemStatement;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ProblemStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;LiteralExpression;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;LiteralExpression;IfStatement;FunctionCallExpression;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IfStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;
-----ast_node-----
static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,				   struct vmcs12 *vmcs12){	struct kvm_segment seg;	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)		vcpu->arch.efer = vmcs12->host_ia32_efer;	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);	vmx_set_efer(vcpu, vcpu->arch.efer);	kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);	kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);	vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);	/*	 * Note that calling vmx_set_cr0 is important, even if cr0 hasn't	 * actually changed, because it depends on the current state of	 * fpu_active (which may have changed).	 * Note that vmx_set_cr0 refers to efer set above.	 */	vmx_set_cr0(vcpu, vmcs12->host_cr0);	/*	 * If we did fpu_activate()/fpu_deactivate() during L2's run, we need	 * to apply the same changes to L1's vmcs. We just set cr0 correctly,	 * but we also need to update cr0_guest_host_mask and exception_bitmap.	 */	update_exception_bitmap(vcpu);	vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);	/*	 * Note that CR4_GUEST_HOST_MASK is already set in the original vmcs01	 * (KVM doesn't change it)- no reason to call set_cr4_guest_host_mask();	 */	vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);	vmx_set_cr4(vcpu, vmcs12->host_cr4);	nested_ept_uninit_mmu_context(vcpu);	kvm_set_cr3(vcpu, vmcs12->host_cr3);	kvm_mmu_reset_context(vcpu);	if (!enable_ept)		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;	if (enable_vpid) {		/*		 * Trivially support vpid by letting L2s share their parent		 * L1's vpid. TODO: move to a more elaborate solution, giving		 * each L2 its own vpid and exposing the vpid feature to L1.		 */		vmx_flush_tlb(vcpu);	}	vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);	vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);	vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);	vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);	vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);	vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);	/* If not VM_EXIT_CLEAR_BNDCFGS, the L2 value propagates to L1.  */	if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)		vmcs_write64(GUEST_BNDCFGS, 0);	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);	/* Set L1 segment info according to Intel SDM	    27.5.2 Loading Host Segment and Descriptor-Table Registers */	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.selector = vmcs12->host_cs_selector,		.type = 11,		.present = 1,		.s = 1,		.g = 1	};	if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		seg.l = 1;	else		seg.db = 1;	vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.type = 3,		.present = 1,		.s = 1,		.db = 1,		.g = 1	};	seg.selector = vmcs12->host_ds_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);	seg.selector = vmcs12->host_es_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);	seg.selector = vmcs12->host_ss_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);	seg.selector = vmcs12->host_fs_selector;	seg.base = vmcs12->host_fs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);	seg.selector = vmcs12->host_gs_selector;	seg.base = vmcs12->host_gs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);	seg = (struct kvm_segment) {		.base = vmcs12->host_tr_base,		.limit = 0x67,		.selector = vmcs12->host_tr_selector,		.type = 11,		.present = 1	};	vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);	kvm_set_dr(vcpu, 7, 0x400);	vmcs_write64(GUEST_IA32_DEBUGCTL, 0);	if (cpu_has_vmx_msr_bitmap())		vmx_set_msr_bitmap(vcpu);	if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);}
static void
load_vmcs12_host_state(struct kvm_vcpu *vcpu,				   struct vmcs12 *vmcs12)
load_vmcs12_host_state
struct kvm_vcpu *vcpu
struct kvm_vcpu
kvm_vcpu
*vcpu
*
vcpu
struct vmcs12 *vmcs12
struct vmcs12
vmcs12
*vmcs12
*
vmcs12
{	struct kvm_segment seg;	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)		vcpu->arch.efer = vmcs12->host_ia32_efer;	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);	vmx_set_efer(vcpu, vcpu->arch.efer);	kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);	kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);	vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);	/*	 * Note that calling vmx_set_cr0 is important, even if cr0 hasn't	 * actually changed, because it depends on the current state of	 * fpu_active (which may have changed).	 * Note that vmx_set_cr0 refers to efer set above.	 */	vmx_set_cr0(vcpu, vmcs12->host_cr0);	/*	 * If we did fpu_activate()/fpu_deactivate() during L2's run, we need	 * to apply the same changes to L1's vmcs. We just set cr0 correctly,	 * but we also need to update cr0_guest_host_mask and exception_bitmap.	 */	update_exception_bitmap(vcpu);	vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);	vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);	/*	 * Note that CR4_GUEST_HOST_MASK is already set in the original vmcs01	 * (KVM doesn't change it)- no reason to call set_cr4_guest_host_mask();	 */	vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);	vmx_set_cr4(vcpu, vmcs12->host_cr4);	nested_ept_uninit_mmu_context(vcpu);	kvm_set_cr3(vcpu, vmcs12->host_cr3);	kvm_mmu_reset_context(vcpu);	if (!enable_ept)		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;	if (enable_vpid) {		/*		 * Trivially support vpid by letting L2s share their parent		 * L1's vpid. TODO: move to a more elaborate solution, giving		 * each L2 its own vpid and exposing the vpid feature to L1.		 */		vmx_flush_tlb(vcpu);	}	vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);	vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);	vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);	vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);	vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);	vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);	/* If not VM_EXIT_CLEAR_BNDCFGS, the L2 value propagates to L1.  */	if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)		vmcs_write64(GUEST_BNDCFGS, 0);	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);	/* Set L1 segment info according to Intel SDM	    27.5.2 Loading Host Segment and Descriptor-Table Registers */	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.selector = vmcs12->host_cs_selector,		.type = 11,		.present = 1,		.s = 1,		.g = 1	};	if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		seg.l = 1;	else		seg.db = 1;	vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);	seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.type = 3,		.present = 1,		.s = 1,		.db = 1,		.g = 1	};	seg.selector = vmcs12->host_ds_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);	seg.selector = vmcs12->host_es_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);	seg.selector = vmcs12->host_ss_selector;	vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);	seg.selector = vmcs12->host_fs_selector;	seg.base = vmcs12->host_fs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);	seg.selector = vmcs12->host_gs_selector;	seg.base = vmcs12->host_gs_base;	vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);	seg = (struct kvm_segment) {		.base = vmcs12->host_tr_base,		.limit = 0x67,		.selector = vmcs12->host_tr_selector,		.type = 11,		.present = 1	};	vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);	kvm_set_dr(vcpu, 7, 0x400);	vmcs_write64(GUEST_IA32_DEBUGCTL, 0);	if (cpu_has_vmx_msr_bitmap())		vmx_set_msr_bitmap(vcpu);	if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);}
struct kvm_segment seg;
struct kvm_segment seg;
struct kvm_segment
kvm_segment
seg
seg
if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)		vcpu->arch.efer = vmcs12->host_ia32_efer;	else if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);
vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_LOAD_IA32_EFER
VM_EXIT_LOAD_IA32_EFER
vcpu->arch.efer = vmcs12->host_ia32_efer;
vcpu->arch.efer = vmcs12->host_ia32_efer
vcpu->arch.efer
vcpu->arch
vcpu
vcpu
arch
efer
vmcs12->host_ia32_efer
vmcs12
vmcs12
host_ia32_efer
if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		vcpu->arch.efer |= (EFER_LMA | EFER_LME);	else		vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);
vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_HOST_ADDR_SPACE_SIZE
VM_EXIT_HOST_ADDR_SPACE_SIZE
vcpu->arch.efer |= (EFER_LMA | EFER_LME);
vcpu->arch.efer |= (EFER_LMA | EFER_LME)
vcpu->arch.efer
vcpu->arch
vcpu
vcpu
arch
efer
(EFER_LMA | EFER_LME)
EFER_LMA | EFER_LME
EFER_LMA
EFER_LMA
EFER_LME
EFER_LME
vcpu->arch.efer &= ~(EFER_LMA | EFER_LME);
vcpu->arch.efer &= ~(EFER_LMA | EFER_LME)
vcpu->arch.efer
vcpu->arch
vcpu
vcpu
arch
efer
~(EFER_LMA | EFER_LME)
(EFER_LMA | EFER_LME)
EFER_LMA | EFER_LME
EFER_LMA
EFER_LMA
EFER_LME
EFER_LME
vmx_set_efer(vcpu, vcpu->arch.efer);
vmx_set_efer(vcpu, vcpu->arch.efer)
vmx_set_efer
vmx_set_efer
vcpu
vcpu
vcpu->arch.efer
vcpu->arch
vcpu
vcpu
arch
efer
kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp);
kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp)
kvm_register_write
kvm_register_write
vcpu
vcpu
VCPU_REGS_RSP
VCPU_REGS_RSP
vmcs12->host_rsp
vmcs12
vmcs12
host_rsp
kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip);
kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip)
kvm_register_write
kvm_register_write
vcpu
vcpu
VCPU_REGS_RIP
VCPU_REGS_RIP
vmcs12->host_rip
vmcs12
vmcs12
host_rip
vmx_set_rflags(vcpu, X86_EFLAGS_FIXED);
vmx_set_rflags(vcpu, X86_EFLAGS_FIXED)
vmx_set_rflags
vmx_set_rflags
vcpu
vcpu
X86_EFLAGS_FIXED
X86_EFLAGS_FIXED
vmx_set_cr0(vcpu, vmcs12->host_cr0);
vmx_set_cr0(vcpu, vmcs12->host_cr0)
vmx_set_cr0
vmx_set_cr0
vcpu
vcpu
vmcs12->host_cr0
vmcs12
vmcs12
host_cr0
update_exception_bitmap(vcpu);
update_exception_bitmap(vcpu)
update_exception_bitmap
update_exception_bitmap
vcpu
vcpu
vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0);
vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0)
vcpu->arch.cr0_guest_owned_bits
vcpu->arch
vcpu
vcpu
arch
cr0_guest_owned_bits
(vcpu->fpu_active ? X86_CR0_TS : 0)
vcpu->fpu_active ? X86_CR0_TS : 0
vcpu->fpu_active
vcpu
vcpu
fpu_active
X86_CR0_TS
X86_CR0_TS
0
vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits);
vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits)
vmcs_writel
vmcs_writel
CR0_GUEST_HOST_MASK
CR0_GUEST_HOST_MASK
~vcpu->arch.cr0_guest_owned_bits
vcpu->arch.cr0_guest_owned_bits
vcpu->arch
vcpu
vcpu
arch
cr0_guest_owned_bits
vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK);
vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK)
vcpu->arch.cr4_guest_owned_bits
vcpu->arch
vcpu
vcpu
arch
cr4_guest_owned_bits
~vmcs_readl(CR4_GUEST_HOST_MASK)
vmcs_readl(CR4_GUEST_HOST_MASK)
vmcs_readl
vmcs_readl
CR4_GUEST_HOST_MASK
CR4_GUEST_HOST_MASK
vmx_set_cr4(vcpu, vmcs12->host_cr4);
vmx_set_cr4(vcpu, vmcs12->host_cr4)
vmx_set_cr4
vmx_set_cr4
vcpu
vcpu
vmcs12->host_cr4
vmcs12
vmcs12
host_cr4
nested_ept_uninit_mmu_context(vcpu);
nested_ept_uninit_mmu_context(vcpu)
nested_ept_uninit_mmu_context
nested_ept_uninit_mmu_context
vcpu
vcpu
kvm_set_cr3(vcpu, vmcs12->host_cr3);
kvm_set_cr3(vcpu, vmcs12->host_cr3)
kvm_set_cr3
kvm_set_cr3
vcpu
vcpu
vmcs12->host_cr3
vmcs12
vmcs12
host_cr3
kvm_mmu_reset_context(vcpu);
kvm_mmu_reset_context(vcpu)
kvm_mmu_reset_context
kvm_mmu_reset_context
vcpu
vcpu
if (!enable_ept)		vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;
!enable_ept
enable_ept
enable_ept
vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault;
vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault
vcpu->arch.walk_mmu->inject_page_fault
vcpu->arch.walk_mmu
vcpu->arch
vcpu
vcpu
arch
walk_mmu
inject_page_fault
kvm_inject_page_fault
kvm_inject_page_fault
if (enable_vpid) {		/*		 * Trivially support vpid by letting L2s share their parent		 * L1's vpid. TODO: move to a more elaborate solution, giving		 * each L2 its own vpid and exposing the vpid feature to L1.		 */		vmx_flush_tlb(vcpu);	}
enable_vpid
enable_vpid
{		/*		 * Trivially support vpid by letting L2s share their parent		 * L1's vpid. TODO: move to a more elaborate solution, giving		 * each L2 its own vpid and exposing the vpid feature to L1.		 */		vmx_flush_tlb(vcpu);	}
vmx_flush_tlb(vcpu);
vmx_flush_tlb(vcpu)
vmx_flush_tlb
vmx_flush_tlb
vcpu
vcpu
vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs);
vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs)
vmcs_write32
vmcs_write32
GUEST_SYSENTER_CS
GUEST_SYSENTER_CS
vmcs12->host_ia32_sysenter_cs
vmcs12
vmcs12
host_ia32_sysenter_cs
vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp);
vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp)
vmcs_writel
vmcs_writel
GUEST_SYSENTER_ESP
GUEST_SYSENTER_ESP
vmcs12->host_ia32_sysenter_esp
vmcs12
vmcs12
host_ia32_sysenter_esp
vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip);
vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip)
vmcs_writel
vmcs_writel
GUEST_SYSENTER_EIP
GUEST_SYSENTER_EIP
vmcs12->host_ia32_sysenter_eip
vmcs12
vmcs12
host_ia32_sysenter_eip
vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base);
vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base)
vmcs_writel
vmcs_writel
GUEST_IDTR_BASE
GUEST_IDTR_BASE
vmcs12->host_idtr_base
vmcs12
vmcs12
host_idtr_base
vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base);
vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base)
vmcs_writel
vmcs_writel
GUEST_GDTR_BASE
GUEST_GDTR_BASE
vmcs12->host_gdtr_base
vmcs12
vmcs12
host_gdtr_base
vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);
vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF)
vmcs_write32
vmcs_write32
GUEST_IDTR_LIMIT
GUEST_IDTR_LIMIT
0xFFFF
vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);
vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF)
vmcs_write32
vmcs_write32
GUEST_GDTR_LIMIT
GUEST_GDTR_LIMIT
0xFFFF
if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)		vmcs_write64(GUEST_BNDCFGS, 0);
vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_CLEAR_BNDCFGS
VM_EXIT_CLEAR_BNDCFGS
vmcs_write64(GUEST_BNDCFGS, 0);
vmcs_write64(GUEST_BNDCFGS, 0)
vmcs_write64
vmcs_write64
GUEST_BNDCFGS
GUEST_BNDCFGS
0
if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT) {		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}
vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_LOAD_IA32_PAT
VM_EXIT_LOAD_IA32_PAT
{		vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);		vcpu->arch.pat = vmcs12->host_ia32_pat;	}
vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat);
vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat)
vmcs_write64
vmcs_write64
GUEST_IA32_PAT
GUEST_IA32_PAT
vmcs12->host_ia32_pat
vmcs12
vmcs12
host_ia32_pat
vcpu->arch.pat = vmcs12->host_ia32_pat;
vcpu->arch.pat = vmcs12->host_ia32_pat
vcpu->arch.pat
vcpu->arch
vcpu
vcpu
arch
pat
vmcs12->host_ia32_pat
vmcs12
vmcs12
host_ia32_pat
if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)		vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);
vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL
VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL
vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl);
vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,			vmcs12->host_ia32_perf_global_ctrl)
vmcs_write64
vmcs_write64
GUEST_IA32_PERF_GLOBAL_CTRL
GUEST_IA32_PERF_GLOBAL_CTRL
vmcs12->host_ia32_perf_global_ctrl
vmcs12
vmcs12
host_ia32_perf_global_ctrl
seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.selector = vmcs12->host_cs_selector,		.type = 11,		.present = 1,		.s = 1,		.g = 1	};
if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)		seg.l = 1;	else		seg.db = 1;
vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE
vmcs12->vm_exit_controls
vmcs12
vmcs12
vm_exit_controls
VM_EXIT_HOST_ADDR_SPACE_SIZE
VM_EXIT_HOST_ADDR_SPACE_SIZE
seg.l = 1;
seg.l = 1
seg.l
seg
seg
l
1
seg.db = 1;
seg.db = 1
seg.db
seg
seg
db
1
vmx_set_segment(vcpu, &seg, VCPU_SREG_CS);
vmx_set_segment(vcpu, &seg, VCPU_SREG_CS)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_CS
VCPU_SREG_CS
seg = (struct kvm_segment) {		.base = 0,		.limit = 0xFFFFFFFF,		.type = 3,		.present = 1,		.s = 1,		.db = 1,		.g = 1	};
seg.selector = vmcs12->host_ds_selector;
seg.selector = vmcs12->host_ds_selector
seg.selector
seg
seg
selector
vmcs12->host_ds_selector
vmcs12
vmcs12
host_ds_selector
vmx_set_segment(vcpu, &seg, VCPU_SREG_DS);
vmx_set_segment(vcpu, &seg, VCPU_SREG_DS)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_DS
VCPU_SREG_DS
seg.selector = vmcs12->host_es_selector;
seg.selector = vmcs12->host_es_selector
seg.selector
seg
seg
selector
vmcs12->host_es_selector
vmcs12
vmcs12
host_es_selector
vmx_set_segment(vcpu, &seg, VCPU_SREG_ES);
vmx_set_segment(vcpu, &seg, VCPU_SREG_ES)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_ES
VCPU_SREG_ES
seg.selector = vmcs12->host_ss_selector;
seg.selector = vmcs12->host_ss_selector
seg.selector
seg
seg
selector
vmcs12->host_ss_selector
vmcs12
vmcs12
host_ss_selector
vmx_set_segment(vcpu, &seg, VCPU_SREG_SS);
vmx_set_segment(vcpu, &seg, VCPU_SREG_SS)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_SS
VCPU_SREG_SS
seg.selector = vmcs12->host_fs_selector;
seg.selector = vmcs12->host_fs_selector
seg.selector
seg
seg
selector
vmcs12->host_fs_selector
vmcs12
vmcs12
host_fs_selector
seg.base = vmcs12->host_fs_base;
seg.base = vmcs12->host_fs_base
seg.base
seg
seg
base
vmcs12->host_fs_base
vmcs12
vmcs12
host_fs_base
vmx_set_segment(vcpu, &seg, VCPU_SREG_FS);
vmx_set_segment(vcpu, &seg, VCPU_SREG_FS)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_FS
VCPU_SREG_FS
seg.selector = vmcs12->host_gs_selector;
seg.selector = vmcs12->host_gs_selector
seg.selector
seg
seg
selector
vmcs12->host_gs_selector
vmcs12
vmcs12
host_gs_selector
seg.base = vmcs12->host_gs_base;
seg.base = vmcs12->host_gs_base
seg.base
seg
seg
base
vmcs12->host_gs_base
vmcs12
vmcs12
host_gs_base
vmx_set_segment(vcpu, &seg, VCPU_SREG_GS);
vmx_set_segment(vcpu, &seg, VCPU_SREG_GS)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_GS
VCPU_SREG_GS
seg = (struct kvm_segment) {		.base = vmcs12->host_tr_base,		.limit = 0x67,		.selector = vmcs12->host_tr_selector,		.type = 11,		.present = 1	};
vmx_set_segment(vcpu, &seg, VCPU_SREG_TR);
vmx_set_segment(vcpu, &seg, VCPU_SREG_TR)
vmx_set_segment
vmx_set_segment
vcpu
vcpu
&seg
seg
seg
VCPU_SREG_TR
VCPU_SREG_TR
kvm_set_dr(vcpu, 7, 0x400);
kvm_set_dr(vcpu, 7, 0x400)
kvm_set_dr
kvm_set_dr
vcpu
vcpu
7
0x400
vmcs_write64(GUEST_IA32_DEBUGCTL, 0);
vmcs_write64(GUEST_IA32_DEBUGCTL, 0)
vmcs_write64
vmcs_write64
GUEST_IA32_DEBUGCTL
GUEST_IA32_DEBUGCTL
0
if (cpu_has_vmx_msr_bitmap())		vmx_set_msr_bitmap(vcpu);
cpu_has_vmx_msr_bitmap()
cpu_has_vmx_msr_bitmap
cpu_has_vmx_msr_bitmap
vmx_set_msr_bitmap(vcpu);
vmx_set_msr_bitmap(vcpu)
vmx_set_msr_bitmap
vmx_set_msr_bitmap
vcpu
vcpu
if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count))		nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);
nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,				vmcs12->vm_exit_msr_load_count)
nested_vmx_load_msr
nested_vmx_load_msr
vcpu
vcpu
vmcs12->vm_exit_msr_load_addr
vmcs12
vmcs12
vm_exit_msr_load_addr
vmcs12->vm_exit_msr_load_count
vmcs12
vmcs12
vm_exit_msr_load_count
nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL);
nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL)
nested_vmx_abort
nested_vmx_abort
vcpu
vcpu
VMX_ABORT_LOAD_HOST_MSR_FAIL
VMX_ABORT_LOAD_HOST_MSR_FAIL
-----joern-----
(131,300,0)
(163,61,0)
(78,268,0)
(147,174,0)
(155,268,0)
(126,90,0)
(86,76,0)
(138,24,0)
(231,16,0)
(182,268,0)
(24,268,0)
(2,119,0)
(183,268,0)
(135,280,0)
(264,327,0)
(69,268,0)
(31,97,0)
(62,5,0)
(251,150,0)
(294,61,0)
(2,32,0)
(325,312,0)
(67,36,0)
(243,192,0)
(269,14,0)
(121,250,0)
(98,38,0)
(86,268,0)
(137,189,0)
(304,32,0)
(201,268,0)
(47,119,0)
(266,57,0)
(214,322,0)
(149,101,0)
(223,156,0)
(157,310,0)
(132,95,0)
(101,68,0)
(173,294,0)
(45,320,0)
(321,131,0)
(227,106,0)
(166,254,0)
(183,190,0)
(302,119,0)
(182,236,0)
(150,251,0)
(190,183,0)
(208,92,0)
(294,76,0)
(246,83,0)
(90,318,0)
(142,47,0)
(224,76,0)
(59,8,0)
(319,204,0)
(192,184,0)
(230,204,0)
(27,57,0)
(212,49,0)
(10,76,0)
(181,268,0)
(85,160,0)
(68,101,0)
(67,268,0)
(318,268,0)
(201,229,0)
(124,4,0)
(78,280,0)
(150,119,0)
(16,156,0)
(261,247,0)
(68,119,0)
(240,119,0)
(41,268,0)
(85,257,0)
(57,76,0)
(9,133,0)
(0,268,0)
(279,136,0)
(274,76,0)
(283,36,0)
(71,162,0)
(148,310,0)
(49,133,0)
(302,46,0)
(257,85,0)
(326,86,0)
(63,287,0)
(109,0,0)
(131,119,0)
(77,124,0)
(17,191,0)
(4,268,0)
(178,113,0)
(176,43,0)
(278,240,0)
(300,131,0)
(291,119,0)
(191,17,0)
(43,237,0)
(287,268,0)
(50,20,0)
(305,20,0)
(295,2,0)
(113,119,0)
(8,76,0)
(190,136,0)
(285,235,0)
(213,40,0)
(106,268,0)
(34,7,0)
(272,156,0)
(315,119,0)
(191,76,0)
(31,119,0)
(204,230,0)
(220,95,0)
(156,16,0)
(97,31,0)
(115,79,0)
(284,113,0)
(247,261,0)
(308,47,0)
(129,257,0)
(88,72,0)
(130,101,0)
(70,244,0)
(105,179,0)
(172,19,0)
(226,113,0)
(275,119,0)
(286,294,0)
(250,76,0)
(20,50,0)
(47,142,0)
(33,10,0)
(281,275,0)
(306,36,0)
(82,0,0)
(234,14,0)
(72,88,0)
(249,215,0)
(136,76,0)
(79,268,0)
(266,75,0)
(256,200,0)
(46,268,0)
(307,119,0)
(52,114,0)
(261,76,0)
(75,266,0)
(60,276,0)
(32,268,0)
(185,229,0)
(88,268,0)
(187,129,0)
(253,172,0)
(310,119,0)
(299,244,0)
(210,120,0)
(61,264,0)
(32,2,0)
(7,76,0)
(93,319,0)
(29,307,0)
(207,47,0)
(274,240,0)
(141,158,0)
(172,119,0)
(322,284,0)
(288,268,0)
(270,136,0)
(158,285,0)
(99,144,0)
(261,268,0)
(197,307,0)
(202,17,0)
(154,322,0)
(39,76,0)
(206,268,0)
(258,268,0)
(233,193,0)
(228,23,0)
(100,266,0)
(218,79,0)
(22,191,0)
(277,129,0)
(51,76,0)
(221,94,0)
(229,215,0)
(211,315,0)
(179,254,0)
(13,268,0)
(19,35,0)
(170,1,0)
(165,31,0)
(236,119,0)
(257,129,0)
(317,236,0)
(14,268,0)
(181,262,0)
(312,76,0)
(318,90,0)
(134,40,0)
(65,262,0)
(160,85,0)
(54,235,0)
(293,291,0)
(28,275,0)
(244,142,0)
(20,119,0)
(296,200,0)
(7,160,0)
(104,194,0)
(255,19,0)
(309,316,0)
(180,250,0)
(87,224,0)
(179,268,0)
(328,291,0)
(276,46,0)
(5,4,0)
(107,86,0)
(38,119,0)
(215,229,0)
(184,192,0)
(174,320,0)
(196,261,0)
(120,198,0)
(39,268,0)
(51,275,0)
(152,162,0)
(307,29,0)
(21,268,0)
(282,124,0)
(198,92,0)
(18,181,0)
(161,184,0)
(114,189,0)
(280,78,0)
(237,43,0)
(37,287,0)
(248,24,0)
(189,114,0)
(204,268,0)
(297,320,0)
(94,1,0)
(235,285,0)
(175,31,0)
(72,119,0)
(298,302,0)
(167,94,0)
(145,5,0)
(225,264,0)
(303,38,0)
(267,195,0)
(264,61,0)
(79,127,0)
(36,119,0)
(312,44,0)
(101,76,0)
(3,88,0)
(101,268,0)
(102,247,0)
(258,76,0)
(311,190,0)
(121,97,0)
(79,76,0)
(259,80,0)
(144,76,0)
(168,192,0)
(133,49,0)
(190,97,0)
(209,302,0)
(230,119,0)
(183,76,0)
(46,302,0)
(320,174,0)
(273,150,0)
(287,76,0)
(284,268,0)
(216,274,0)
(314,268,0)
(74,268,0)
(181,76,0)
(193,76,0)
(205,193,0)
(323,182,0)
(188,235,0)
(53,199,0)
(186,10,0)
(291,10,0)
(95,199,0)
(200,78,0)
(25,150,0)
(114,268,0)
(310,23,0)
(262,181,0)
(198,268,0)
(171,236,0)
(29,35,0)
(301,68,0)
(241,43,0)
(112,237,0)
(26,271,0)
(94,119,0)
(108,300,0)
(275,51,0)
(190,285,0)
(195,75,0)
(156,76,0)
(194,76,0)
(192,119,0)
(117,240,0)
(58,194,0)
(106,38,0)
(289,315,0)
(267,76,0)
(49,268,0)
(38,106,0)
(158,193,0)
(73,72,0)
(61,294,0)
(136,190,0)
(30,68,0)
(254,179,0)
(191,268,0)
(140,72,0)
(57,266,0)
(280,119,0)
(316,86,0)
(113,284,0)
(238,268,0)
(142,268,0)
(122,55,0)
(64,39,0)
(48,268,0)
(84,90,0)
(56,39,0)
(151,8,0)
(195,267,0)
(169,7,0)
(10,291,0)
(40,318,0)
(16,29,0)
(75,268,0)
(179,76,0)
(124,119,0)
(19,172,0)
(252,172,0)
(164,280,0)
(159,268,0)
(313,20,0)
(203,191,0)
(83,76,0)
(290,261,0)
(81,57,0)
(144,268,0)
(274,315,0)
(177,50,0)
(232,327,0)
(89,268,0)
(162,80,0)
(8,120,0)
(193,158,0)
(245,267,0)
(1,94,0)
(42,127,0)
(92,198,0)
(146,195,0)
(139,114,0)
(324,131,0)
(240,274,0)
(224,268,0)
(260,183,0)
(50,268,0)
(315,274,0)
(239,121,0)
(242,133,0)
(292,67,0)
(123,215,0)
(11,251,0)
(106,76,0)
(160,7,0)
(6,201,0)
(49,76,0)
(43,119,0)
(265,55,0)
(229,201,0)
(133,119,0)
(263,258,0)
(222,51,0)
(118,181,0)
(90,119,0)
(23,310,0)
(250,121,0)
(15,267,0)
(86,316,0)
(36,67,0)
(128,250,0)
(91,307,0)
(153,266,0)
(96,287,0)
(114,76,0)
(4,124,0)
(51,268,0)
(219,230,0)
(10,268,0)
(320,119,0)
(111,179,0)
(143,2,0)
(127,79,0)
(66,160,0)
(120,8,0)
(116,319,0)
(12,230,0)
(236,182,0)
(103,276,0)
(299,114,1)
(40,134,1)
(156,76,1)
(102,196,1)
(250,180,1)
(184,161,1)
(120,8,1)
(114,189,1)
(60,103,1)
(187,277,1)
(300,108,1)
(179,76,1)
(207,308,1)
(267,76,1)
(70,299,1)
(292,110,1)
(148,184,1)
(114,76,1)
(182,236,1)
(275,281,1)
(20,313,1)
(294,286,1)
(174,320,1)
(120,210,1)
(227,224,1)
(229,215,1)
(195,146,1)
(31,165,1)
(110,327,1)
(192,168,1)
(277,160,1)
(315,119,1)
(259,162,1)
(200,296,1)
(2,119,1)
(1,94,1)
(20,119,1)
(309,326,1)
(128,174,1)
(294,76,1)
(280,135,1)
(84,126,1)
(255,23,1)
(164,200,1)
(124,119,1)
(160,66,1)
(275,119,1)
(91,197,1)
(142,47,1)
(123,6,1)
(42,115,1)
(100,57,1)
(274,315,1)
(125,274,1)
(257,129,1)
(136,76,1)
(167,237,1)
(47,207,1)
(79,127,1)
(65,18,1)
(118,262,1)
(27,195,1)
(226,178,1)
(260,285,1)
(95,132,1)
(38,119,1)
(172,252,1)
(103,261,1)
(235,54,1)
(274,240,1)
(36,306,1)
(38,303,1)
(251,150,1)
(66,7,1)
(286,173,1)
(166,105,1)
(16,231,1)
(10,291,1)
(134,213,1)
(278,216,1)
(184,192,1)
(247,102,1)
(289,240,1)
(23,228,1)
(162,152,1)
(301,149,1)
(92,208,1)
(64,101,1)
(302,209,1)
(107,316,1)
(7,34,1)
(58,104,1)
(232,264,1)
(196,199,1)
(86,76,1)
(262,65,1)
(14,269,1)
(158,141,1)
(237,43,1)
(139,189,1)
(192,119,1)
(190,311,1)
(321,23,1)
(3,50,1)
(87,49,1)
(52,204,1)
(43,119,1)
(132,220,1)
(291,293,1)
(17,202,1)
(283,292,1)
(327,232,1)
(202,203,1)
(127,42,1)
(24,248,1)
(208,120,1)
(253,255,1)
(220,1,1)
(71,1,1)
(185,215,1)
(49,76,1)
(147,320,1)
(270,260,1)
(210,8,1)
(31,119,1)
(264,225,1)
(319,116,1)
(55,122,1)
(148,55,1)
(193,76,1)
(163,294,1)
(231,156,1)
(28,222,1)
(323,67,1)
(75,266,1)
(313,305,1)
(229,185,1)
(135,164,1)
(320,119,1)
(104,274,1)
(67,36,1)
(170,94,1)
(158,193,1)
(196,80,1)
(285,235,1)
(53,95,1)
(281,28,1)
(133,119,1)
(161,192,1)
(106,38,1)
(141,193,1)
(149,130,1)
(176,241,1)
(116,93,1)
(317,171,1)
(326,284,1)
(300,131,1)
(260,85,1)
(194,76,1)
(190,97,1)
(22,17,1)
(129,187,1)
(152,71,1)
(8,59,1)
(46,302,1)
(62,142,1)
(260,97,1)
(245,144,1)
(150,119,1)
(108,131,1)
(204,230,1)
(122,265,1)
(244,70,1)
(172,119,1)
(112,300,1)
(248,138,1)
(179,111,1)
(51,76,1)
(252,253,1)
(174,147,1)
(199,53,1)
(68,30,1)
(223,272,1)
(251,11,1)
(15,245,1)
(181,118,1)
(214,154,1)
(51,275,1)
(216,83,1)
(254,166,1)
(211,289,1)
(287,76,1)
(243,14,1)
(45,297,1)
(249,123,1)
(217,0,1)
(121,250,1)
(269,234,1)
(218,127,1)
(29,307,1)
(190,136,1)
(157,148,1)
(266,100,1)
(23,310,1)
(93,191,1)
(18,86,1)
(146,267,1)
(79,218,1)
(261,247,1)
(50,20,1)
(57,81,1)
(82,109,1)
(8,76,1)
(168,243,1)
(153,57,1)
(306,283,1)
(221,167,1)
(143,304,1)
(39,76,1)
(144,76,1)
(0,82,1)
(111,254,1)
(266,57,1)
(4,124,1)
(287,96,1)
(54,188,1)
(272,19,1)
(131,119,1)
(316,309,1)
(47,119,1)
(302,119,1)
(312,325,1)
(263,106,1)
(267,15,1)
(97,31,1)
(130,10,1)
(190,285,1)
(280,119,1)
(318,90,1)
(34,169,1)
(56,64,1)
(256,79,1)
(10,76,1)
(33,186,1)
(140,73,1)
(195,267,1)
(36,119,1)
(181,76,1)
(73,3,1)
(151,201,1)
(145,62,1)
(160,7,1)
(105,4,1)
(154,318,1)
(68,119,1)
(16,156,1)
(136,279,1)
(282,5,1)
(169,251,1)
(258,263,1)
(322,214,1)
(265,184,1)
(178,322,1)
(43,176,1)
(83,76,1)
(109,287,1)
(90,84,1)
(85,160,1)
(12,219,1)
(284,113,1)
(209,298,1)
(274,76,1)
(5,145,1)
(240,119,1)
(96,63,1)
(295,143,1)
(312,76,1)
(276,60,1)
(311,136,1)
(133,242,1)
(156,223,1)
(250,76,1)
(77,282,1)
(240,117,1)
(224,87,1)
(236,119,1)
(305,177,1)
(106,76,1)
(167,300,1)
(188,158,1)
(124,77,1)
(191,17,1)
(303,98,1)
(72,119,1)
(180,128,1)
(63,37,1)
(239,250,1)
(225,61,1)
(131,324,1)
(212,198,1)
(61,163,1)
(113,119,1)
(197,16,1)
(193,205,1)
(57,76,1)
(271,26,1)
(213,179,1)
(310,119,1)
(261,290,1)
(126,40,1)
(6,75,1)
(90,119,1)
(205,233,1)
(291,119,1)
(81,27,1)
(11,150,1)
(9,212,1)
(203,78,1)
(215,249,1)
(308,244,1)
(236,317,1)
(246,217,1)
(290,247,1)
(165,175,1)
(216,217,1)
(242,9,1)
(125,194,1)
(117,278,1)
(1,170,1)
(328,33,1)
(298,276,1)
(150,273,1)
(113,226,1)
(201,229,1)
(266,153,1)
(307,91,1)
(325,110,1)
(320,45,1)
(25,174,1)
(324,321,1)
(279,270,1)
(49,133,1)
(88,72,1)
(222,39,1)
(72,140,1)
(233,251,1)
(175,121,1)
(191,76,1)
(32,2,1)
(310,157,1)
(138,88,1)
(177,32,1)
(30,301,1)
(304,182,1)
(264,61,1)
(85,257,1)
(171,323,1)
(78,280,1)
(37,181,1)
(293,328,1)
(241,112,1)
(191,22,1)
(292,312,1)
(110,271,1)
(137,52,1)
(230,12,1)
(179,254,1)
(183,190,1)
(198,92,1)
(26,258,1)
(115,46,1)
(98,227,1)
(186,183,1)
(19,172,1)
(83,246,1)
(219,319,1)
(61,294,1)
(261,76,1)
(173,271,1)
(296,256,1)
(121,239,1)
(99,51,1)
(114,139,1)
(228,310,1)
(224,76,1)
(181,262,1)
(321,29,1)
(307,119,1)
(86,316,1)
(59,151,1)
(101,76,1)
(7,76,1)
(230,119,1)
(273,25,1)
(194,58,1)
(79,76,1)
(183,76,1)
(189,137,1)
(80,259,1)
(2,295,1)
(234,24,1)
(101,68,1)
(94,119,1)
(258,76,1)
(86,107,1)
(315,211,1)
(39,56,1)
(94,221,1)
(144,99,1)
(190,136,2)
(307,119,2)
(183,190,2)
(25,174,2)
(274,76,2)
(49,133,2)
(16,156,2)
(253,23,2)
(223,23,2)
(7,76,2)
(29,307,2)
(121,250,2)
(182,236,2)
(194,76,2)
(267,76,2)
(136,76,2)
(195,267,2)
(287,76,2)
(106,38,2)
(250,76,2)
(67,36,2)
(180,174,2)
(225,271,2)
(187,251,2)
(291,119,2)
(85,251,2)
(79,76,2)
(120,8,2)
(153,57,2)
(300,131,2)
(121,174,2)
(266,57,2)
(191,17,2)
(8,76,2)
(10,291,2)
(68,119,2)
(229,215,2)
(97,31,2)
(104,274,2)
(240,119,2)
(85,160,2)
(32,2,2)
(61,294,2)
(51,76,2)
(312,76,2)
(274,240,2)
(265,184,2)
(49,76,2)
(220,1,2)
(237,300,2)
(310,119,2)
(86,316,2)
(190,97,2)
(50,20,2)
(34,251,2)
(264,271,2)
(78,280,2)
(275,119,2)
(232,271,2)
(158,251,2)
(261,76,2)
(16,23,2)
(11,174,2)
(173,271,2)
(88,72,2)
(112,300,2)
(114,76,2)
(230,119,2)
(66,251,2)
(162,1,2)
(205,251,2)
(163,271,2)
(252,23,2)
(106,76,2)
(39,76,2)
(97,174,2)
(54,251,2)
(20,119,2)
(55,184,2)
(94,119,2)
(57,76,2)
(61,271,2)
(193,251,2)
(36,119,2)
(132,1,2)
(43,119,2)
(197,23,2)
(175,174,2)
(320,119,2)
(250,174,2)
(325,110,2)
(142,47,2)
(257,251,2)
(141,251,2)
(285,251,2)
(307,23,2)
(129,251,2)
(273,174,2)
(144,76,2)
(188,251,2)
(23,310,2)
(53,1,2)
(172,119,2)
(165,174,2)
(83,76,2)
(114,189,2)
(150,119,2)
(176,300,2)
(284,113,2)
(285,235,2)
(174,320,2)
(100,57,2)
(231,23,2)
(259,1,2)
(172,23,2)
(237,43,2)
(31,174,2)
(31,119,2)
(280,119,2)
(294,271,2)
(204,230,2)
(272,23,2)
(71,1,2)
(128,174,2)
(156,23,2)
(192,119,2)
(169,251,2)
(156,76,2)
(179,76,2)
(181,76,2)
(274,315,2)
(43,300,2)
(80,1,2)
(101,76,2)
(46,302,2)
(239,174,2)
(184,192,2)
(150,174,2)
(10,76,2)
(101,68,2)
(133,119,2)
(277,251,2)
(38,119,2)
(83,217,2)
(235,251,2)
(85,257,2)
(201,229,2)
(160,251,2)
(261,247,2)
(90,119,2)
(255,23,2)
(47,119,2)
(75,266,2)
(2,119,2)
(113,119,2)
(194,274,2)
(91,23,2)
(122,184,2)
(7,251,2)
(191,76,2)
(19,172,2)
(19,23,2)
(312,110,2)
(302,119,2)
(246,217,2)
(236,119,2)
(241,300,2)
(327,271,2)
(258,76,2)
(183,76,2)
(51,275,2)
(131,119,2)
(160,7,2)
(124,119,2)
(58,274,2)
(233,251,2)
(224,76,2)
(4,124,2)
(152,1,2)
(257,129,2)
(79,127,2)
(294,76,2)
(251,174,2)
(193,76,2)
(199,1,2)
(72,119,2)
(286,271,2)
(158,193,2)
(29,23,2)
(86,76,2)
(179,254,2)
(1,94,2)
(181,262,2)
(190,285,2)
(264,61,2)
(315,119,2)
(95,1,2)
(198,92,2)
(251,150,2)
(318,90,2)
-----------------------------------
(0,vmcs_write64(GUEST_IA32_DEBUGCTL, 0)
(1,vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)
(2,vmcs12->host_ia32_sysenter_eip)
(3,GUEST_GDTR_BASE)
(4,seg.base = vmcs12->host_fs_base)
(5,seg.base)
(6,CR0_GUEST_HOST_MASK)
(7,vcpu->arch)
(8,vcpu->arch)
(9,vmcs12)
(10,kvm_register_write(vcpu, VCPU_REGS_RSP, vmcs12->host_rsp)
(11,VM_EXIT_HOST_ADDR_SPACE_SIZE)
(12,host_ss_selector)
(13,if (vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)
(14,vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF)
(15,arch)
(16,vcpu->arch.pat)
(17,&seg)
(18,vcpu)
(19,vmcs_write64(GUEST_IA32_PAT, vmcs12->host_ia32_pat)
(20,vmcs12->host_idtr_base)
(21,if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT)
(22,VCPU_SREG_ES)
(23,vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PAT)
(24,vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF)
(25,vmcs12)
(26,enable_ept)
(27,vcpu)
(28,vmcs12)
(29,vcpu->arch.pat = vmcs12->host_ia32_pat)
(30,host_rip)
(31,vmcs12->host_ia32_efer)
(32,vmcs_writel(GUEST_SYSENTER_EIP, vmcs12->host_ia32_sysenter_eip)
(33,VCPU_REGS_RSP)
(34,arch)
(35,)
(36,vmcs12->host_ia32_sysenter_cs)
(37,vcpu)
(38,vmcs12->host_cr3)
(39,vmx_set_rflags(vcpu, X86_EFLAGS_FIXED)
(40,seg.selector)
(41,if (nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,\n\\n\\t\\t\\t\\tvmcs12->vm_exit_msr_load_count)
(42,seg)
(43,vmcs12->host_ia32_perf_global_ctrl)
(44,)
(45,vm_exit_controls)
(46,seg.selector = vmcs12->host_ds_selector)
(47,vmcs12->host_fs_selector)
(48,if (vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)
(49,vmx_set_cr4(vcpu, vmcs12->host_cr4)
(50,vmcs_writel(GUEST_IDTR_BASE, vmcs12->host_idtr_base)
(51,vmx_set_cr0(vcpu, vmcs12->host_cr0)
(52,vcpu)
(53,1)
(54,EFER_LME)
(55,vmcs_write64(GUEST_BNDCFGS, 0)
(56,X86_EFLAGS_FIXED)
(57,vcpu->fpu_active)
(58,VMX_ABORT_LOAD_HOST_MSR_FAIL)
(59,arch)
(60,selector)
(61,vcpu->arch.walk_mmu)
(62,seg)
(63,7)
(64,vcpu)
(65,seg)
(66,efer)
(67,vmcs_write32(GUEST_SYSENTER_CS, vmcs12->host_ia32_sysenter_cs)
(68,vmcs12->host_rip)
(69,)
(70,selector)
(71,seg)
(72,vmcs12->host_gdtr_base)
(73,vmcs12)
(74,if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)
(75,vcpu->arch.cr0_guest_owned_bits = (vcpu->fpu_active ? X86_CR0_TS : 0)
(76,struct kvm_vcpu *vcpu)
(77,host_fs_base)
(78,seg.selector = vmcs12->host_es_selector)
(79,vmx_set_segment(vcpu, &seg, VCPU_SREG_DS)
(80,seg.l = 1)
(81,fpu_active)
(82,0)
(83,vmx_set_msr_bitmap(vcpu)
(84,host_gs_selector)
(85,vcpu->arch.efer &= ~(EFER_LMA | EFER_LME)
(86,vmx_set_segment(vcpu, &seg, VCPU_SREG_GS)
(87,vcpu)
(88,vmcs_writel(GUEST_GDTR_BASE, vmcs12->host_gdtr_base)
(89,if (enable_vpid)
(90,vmcs12->host_gs_selector)
(91,host_ia32_pat)
(92,~vmcs_readl(CR4_GUEST_HOST_MASK)
(93,seg)
(94,vmcs12->vm_exit_controls)
(95,seg.db)
(96,0x400)
(97,vcpu->arch.efer = vmcs12->host_ia32_efer)
(98,vmcs12)
(99,vcpu)
(100,X86_CR0_TS)
(101,kvm_register_write(vcpu, VCPU_REGS_RIP, vmcs12->host_rip)
(102,seg)
(103,seg)
(104,vcpu)
(105,vcpu)
(106,kvm_set_cr3(vcpu, vmcs12->host_cr3)
(107,VCPU_SREG_GS)
(108,VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)
(109,GUEST_IA32_DEBUGCTL)
(110,enable_vpid)
(111,VCPU_SREG_FS)
(112,GUEST_IA32_PERF_GLOBAL_CTRL)
(113,vmcs12->host_gs_base)
(114,vmx_set_segment(vcpu, &seg, VCPU_SREG_SS)
(115,vcpu)
(116,selector)
(117,vm_exit_msr_load_addr)
(118,VCPU_SREG_TR)
(119,struct vmcs12 *vmcs12)
(120,vcpu->arch.cr4_guest_owned_bits)
(121,vcpu->arch.efer)
(122,0)
(123,~vcpu)
(124,vmcs12->host_fs_base)
(125,RET)
(126,vmcs12)
(127,&seg)
(128,vcpu)
(129,EFER_LMA | EFER_LME)
(130,vcpu)
(131,vmcs12->vm_exit_controls)
(132,db)
(133,vmcs12->host_cr4)
(134,selector)
(135,host_es_selector)
(136,vcpu->arch)
(137,seg)
(138,GUEST_IDTR_LIMIT)
(139,VCPU_SREG_SS)
(140,host_gdtr_base)
(141,efer)
(142,seg.selector = vmcs12->host_fs_selector)
(143,vmcs12)
(144,update_exception_bitmap(vcpu)
(145,base)
(146,cr0_guest_owned_bits)
(147,VM_EXIT_LOAD_IA32_EFER)
(148,vmcs12)
(149,VCPU_REGS_RIP)
(150,vmcs12->vm_exit_controls)
(151,vcpu)
(152,l)
(153,0)
(154,seg)
(155,if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)
(156,vcpu->arch)
(157,vm_exit_controls)
(158,vcpu->arch.efer)
(159,)
(160,vcpu->arch.efer)
(161,VM_EXIT_CLEAR_BNDCFGS)
(162,seg.l)
(163,walk_mmu)
(164,vmcs12)
(165,host_ia32_efer)
(166,seg)
(167,vmcs12)
(168,vm_exit_controls)
(169,vcpu)
(170,VM_EXIT_HOST_ADDR_SPACE_SIZE)
(171,vmcs12)
(172,vmcs12->host_ia32_pat)
(173,vcpu)
(174,vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER)
(175,vmcs12)
(176,host_ia32_perf_global_ctrl)
(177,GUEST_IDTR_BASE)
(178,vmcs12)
(179,vmx_set_segment(vcpu, &seg, VCPU_SREG_FS)
(180,arch)
(181,vmx_set_segment(vcpu, &seg, VCPU_SREG_TR)
(182,vmcs_writel(GUEST_SYSENTER_ESP, vmcs12->host_ia32_sysenter_esp)
(183,vmx_set_efer(vcpu, vcpu->arch.efer)
(184,vmcs12->vm_exit_controls & VM_EXIT_CLEAR_BNDCFGS)
(185,cr0_guest_owned_bits)
(186,vcpu)
(187,EFER_LME)
(188,EFER_LMA)
(189,&seg)
(190,vcpu->arch.efer)
(191,vmx_set_segment(vcpu, &seg, VCPU_SREG_ES)
(192,vmcs12->vm_exit_controls)
(193,vcpu->arch)
(194,nested_vmx_abort(vcpu, VMX_ABORT_LOAD_HOST_MSR_FAIL)
(195,vcpu->arch.cr0_guest_owned_bits)
(196,vcpu)
(197,vmcs12)
(198,vcpu->arch.cr4_guest_owned_bits = ~vmcs_readl(CR4_GUEST_HOST_MASK)
(199,seg.db = 1)
(200,seg.selector)
(201,vmcs_writel(CR0_GUEST_HOST_MASK, ~vcpu->arch.cr0_guest_owned_bits)
(202,seg)
(203,vcpu)
(204,seg.selector = vmcs12->host_ss_selector)
(205,arch)
(206,if (cpu_has_vmx_msr_bitmap()
(207,host_fs_selector)
(208,CR4_GUEST_HOST_MASK)
(209,host_ds_selector)
(210,cr4_guest_owned_bits)
(211,vm_exit_msr_load_count)
(212,vcpu)
(213,seg)
(214,base)
(215,~vcpu->arch)
(216,vcpu)
(217,cpu_has_vmx_msr_bitmap()
(218,VCPU_SREG_DS)
(219,vmcs12)
(220,seg)
(221,vm_exit_controls)
(222,vcpu)
(223,arch)
(224,nested_ept_uninit_mmu_context(vcpu)
(225,inject_page_fault)
(226,host_gs_base)
(227,vcpu)
(228,VM_EXIT_LOAD_IA32_PAT)
(229,~vcpu->arch.cr0_guest_owned_bits)
(230,vmcs12->host_ss_selector)
(231,pat)
(232,kvm_inject_page_fault)
(233,vcpu)
(234,GUEST_GDTR_LIMIT)
(235,EFER_LMA | EFER_LME)
(236,vmcs12->host_ia32_sysenter_esp)
(237,vmcs_write64(GUEST_IA32_PERF_GLOBAL_CTRL,\n\\n\\t\\t\\tvmcs12->host_ia32_perf_global_ctrl)
(238,if (!enable_ept)
(239,efer)
(240,vmcs12->vm_exit_msr_load_addr)
(241,vmcs12)
(242,host_cr4)
(243,vmcs12)
(244,seg.selector)
(245,vcpu)
(246,vcpu)
(247,&seg)
(248,0xFFFF)
(249,arch)
(250,vcpu->arch)
(251,vmcs12->vm_exit_controls & VM_EXIT_HOST_ADDR_SPACE_SIZE)
(252,host_ia32_pat)
(253,vmcs12)
(254,&seg)
(255,GUEST_IA32_PAT)
(256,seg)
(257,~(EFER_LMA | EFER_LME)
(258,kvm_mmu_reset_context(vcpu)
(259,1)
(260,vcpu)
(261,vmx_set_segment(vcpu, &seg, VCPU_SREG_CS)
(262,&seg)
(263,vcpu)
(264,vcpu->arch.walk_mmu->inject_page_fault)
(265,GUEST_BNDCFGS)
(266,vcpu->fpu_active ? X86_CR0_TS : 0)
(267,vcpu->arch)
(268,)
(269,0xFFFF)
(270,vcpu)
(271,!enable_ept)
(272,vcpu)
(273,vm_exit_controls)
(274,nested_vmx_load_msr(vcpu, vmcs12->vm_exit_msr_load_addr,\n\\n\\t\\t\\t\\tvmcs12->vm_exit_msr_load_count)
(275,vmcs12->host_cr0)
(276,seg.selector)
(277,EFER_LMA)
(278,vmcs12)
(279,arch)
(280,vmcs12->host_es_selector)
(281,host_cr0)
(282,vmcs12)
(283,vmcs12)
(284,seg.base = vmcs12->host_gs_base)
(285,vcpu->arch.efer |= (EFER_LMA | EFER_LME)
(286,arch)
(287,kvm_set_dr(vcpu, 7, 0x400)
(288,)
(289,vmcs12)
(290,VCPU_SREG_CS)
(291,vmcs12->host_rsp)
(292,GUEST_SYSENTER_CS)
(293,host_rsp)
(294,vcpu->arch)
(295,host_ia32_sysenter_eip)
(296,selector)
(297,vmcs12)
(298,vmcs12)
(299,seg)
(300,vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_PERF_GLOBAL_CTRL)
(301,vmcs12)
(302,vmcs12->host_ds_selector)
(303,host_cr3)
(304,GUEST_SYSENTER_EIP)
(305,vmcs12)
(306,host_ia32_sysenter_cs)
(307,vmcs12->host_ia32_pat)
(308,vmcs12)
(309,seg)
(310,vmcs12->vm_exit_controls)
(311,efer)
(312,vmx_flush_tlb(vcpu)
(313,host_idtr_base)
(314,seg)
(315,vmcs12->vm_exit_msr_load_count)
(316,&seg)
(317,host_ia32_sysenter_esp)
(318,seg.selector = vmcs12->host_gs_selector)
(319,seg.selector)
(320,vmcs12->vm_exit_controls)
(321,vmcs12)
(322,seg.base)
(323,GUEST_SYSENTER_ESP)
(324,vm_exit_controls)
(325,vcpu)
(326,vcpu)
(327,vcpu->arch.walk_mmu->inject_page_fault = kvm_inject_page_fault)
(328,vmcs12)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
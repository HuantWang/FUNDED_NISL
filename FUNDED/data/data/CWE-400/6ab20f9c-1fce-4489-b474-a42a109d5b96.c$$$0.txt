-----label-----
1
-----code-----
void
thread_lock_released(const void *lock, enum thread_lock_kind kind,
	const void *element)
{
	struct thread_element *te = deconstify_pointer(element);
	struct thread_lock_stack *tls;
	const struct thread_lock *l;
	unsigned i;

	/*
	 * For the same reasons as in thread_lock_got(), lazily grab the thread
	 * element.  Note that we may be in a situation where we did not get a
	 * thread element at lock time but are able to get one now.
	 */

	if (NULL == te) {
		te = thread_find(&te);
	} else {
		thread_element_check(te);
	}

	if G_UNLIKELY(NULL == te)
		return;

	tls = &te->locks;

	if G_UNLIKELY(0 == tls->count) {
		/*
		 * Warn only if we have seen a lock once (te->stack_lock != NULL)
		 * and when the stack is larger than the first lock acquired.
		 *
		 * Otherwise, it means that we're poping out from the place where
		 * we first recorded a lock, and therefore it is obvious we cannot
		 * have the lock recorded since we're before the call chain that
		 * could record the first lock.
		 */

		if (
			te->stack_lock != NULL &&
			thread_stack_ptr_cmp(&te, te->stack_lock) >= 0
		) {
			s_minicarp("%s(): %s %p was not registered in thread #%u",
				G_STRFUNC, thread_lock_kind_to_string(kind), lock, te->stid);
		}
		return;
	}

	/*
	 * If lock is the top of the stack, we're done.
	 */

	l = &tls->arena[tls->count - 1];

	if G_LIKELY(l->lock == lock) {
		g_assert_log(l->kind == kind,
			"%s(): %s %p is actually registered as %s in thread #%u",
			G_STRFUNC, thread_lock_kind_to_string(kind), lock,
			thread_lock_kind_to_string(l->kind), te->stid);

		tls->count--;

		/*
		 * Handle signals if any are pending and can be delivered.
		 */

		if G_UNLIKELY(thread_sig_pending(te)) {
			THREAD_STATS_INCX(sig_handled_while_unlocking);
			thread_sig_handle(te);
		}

		/*
		 * If the thread no longer holds any locks and it has to be suspended,
		 * now is a good (and safe) time to do it.
		 */

		if G_UNLIKELY(te->suspend && 0 == tls->count)
			thread_suspend_self(te);

		return;
	}

	/*
	 * Since the lock was not the one at the top of the stack, then it must be
	 * absent in the whole stack, or we have an out-of-order lock release.
	 */

	if (tls->overflow)
		return;				/* Stack overflowed, we're crashing */

	for (i = 0; i < tls->count; i++) {
		const struct thread_lock *ol = &tls->arena[i];

		if (ol->lock == lock) {
			tls->overflow = TRUE;	/* Avoid any overflow problems now */
			s_rawwarn("%s releases %s %p at inner position %u/%zu",
				thread_element_name(te), thread_lock_kind_to_string(kind),
				lock, i + 1, tls->count);
			thread_lock_dump(te);

			/*
			 * If crashing, it's interesting to learn about possible
			 * out-of-order unlocking, because it may point to a true
			 * bug in the crash handling, but let processing continue
			 * to be able to dump useful information anyway.
			 */

			if (
				!thread_is_crashing() &&
				0 == atomic_int_get(&thread_locks_disabled)
			) {
				s_error("out-of-order %s release",
					thread_lock_kind_to_string(kind));
			}
		}
	}
}
-----children-----
1,2
1,3
1,4
3,4
3,5
3,6
3,7
5,6
5,7
7,8
7,9
10,11
10,12
11,12
13,14
15,16
15,17
17,18
17,19
20,21
20,22
20,23
20,24
20,25
20,26
20,27
20,28
20,29
20,30
20,31
20,32
21,22
22,23
22,24
23,24
25,26
25,27
25,28
28,29
29,30
29,31
30,31
32,33
34,35
35,36
35,37
36,37
38,39
38,40
41,42
42,43
42,44
43,44
45,46
45,47
48,49
49,50
49,51
51,52
53,54
53,55
53,56
54,55
54,56
55,56
57,58
59,60
60,61
61,62
61,63
62,63
64,65
64,66
65,66
67,68
68,69
70,71
71,72
72,73
72,74
73,74
75,76
77,78
78,79
79,80
79,81
80,81
82,83
83,84
83,85
84,85
87,88
88,89
89,90
89,91
90,91
92,93
93,94
93,95
94,95
94,96
95,96
98,99
98,100
99,100
99,101
100,101
104,105
105,106
105,107
106,107
106,108
107,108
111,112
111,113
111,114
111,115
112,113
113,114
113,115
114,115
117,118
117,119
118,119
120,121
120,122
121,122
124,125
125,126
127,128
127,129
128,129
129,130
129,131
130,131
132,133
132,134
132,135
135,136
136,137
137,138
137,139
138,139
138,140
139,140
142,143
144,145
144,146
145,146
145,147
146,147
146,148
147,148
150,151
152,153
152,154
152,155
152,156
153,154
154,155
154,156
155,156
155,157
156,157
159,160
161,162
162,163
162,164
162,165
162,166
162,167
162,168
162,169
163,164
166,167
166,168
167,168
169,170
171,172
171,173
172,173
174,175
176,177
178,179
178,180
179,180
182,183
182,184
183,184
186,187
187,188
187,189
188,189
190,191
192,193
192,194
193,194
193,195
194,195
195,196
196,197
198,199
198,200
200,201
200,202
201,202
203,204
204,205
206,207
207,208
208,209
208,210
208,211
209,210
212,213
212,214
213,214
215,216
-----nextToken-----
2,4,6,8,9,12,14,16,18,19,24,26,27,31,33,37,39,40,44,46,47,50,52,56,58,63,66,69,74,76,81,85,86,91,96,97,101,102,103,108,109,110,115,116,119,122,123,126,131,133,134,140,141,143,148,149,151,157,158,160,164,165,168,170,173,175,177,180,181,184,185,189,191,197,199,202,205,210,211,214,216
-----computeFrom-----
54,55
54,56
61,62
61,63
79,80
79,81
89,90
89,91
98,99
98,100
113,114
113,115
117,118
117,119
145,146
145,147
154,155
154,156
178,179
178,180
193,194
193,195
198,199
198,200
-----guardedBy-----
58,69
151,177
-----guardedByNegation-----
58,76
-----lastLexicalUse-----
58,76
-----jump-----
58,76
-----attribute-----
FunctionDefinition;SimpleDeclSpecifier;FunctionDeclarator;Name;ParameterDeclaration;SimpleDeclSpecifier;Declarator;Pointer;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Name;ParameterDeclaration;SimpleDeclSpecifier;Declarator;Pointer;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;EqualsInitializer;FunctionCallExpression;IdExpression;Name;IdExpression;Name;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;DeclarationStatement;SimpleDeclaration;SimpleDeclSpecifier;Declarator;Name;IfStatement;BinaryExpression;IdExpression;Name;IdExpression;Name;CompoundStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;FunctionCallExpression;IdExpression;Name;UnaryExpression;IdExpression;Name;CompoundStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ProblemStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;UnaryExpression;FieldReference;IdExpression;Name;Name;ProblemStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;UnaryExpression;ArraySubscriptExpression;FieldReference;IdExpression;Name;Name;BinaryExpression;FieldReference;IdExpression;Name;Name;LiteralExpression;ProblemStatement;IfStatement;FieldReference;IdExpression;Name;Name;ReturnStatement;ForStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;LiteralExpression;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;UnaryExpression;IdExpression;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;EqualsInitializer;UnaryExpression;ArraySubscriptExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;IfStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;CompoundStatement;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;LiteralExpression;FunctionCallExpression;IdExpression;Name;IdExpression;Name;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;BinaryExpression;IdExpression;Name;LiteralExpression;FieldReference;IdExpression;Name;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IfStatement;BinaryExpression;UnaryExpression;FunctionCallExpression;IdExpression;Name;BinaryExpression;LiteralExpression;FunctionCallExpression;IdExpression;Name;UnaryExpression;IdExpression;Name;CompoundStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;LiteralExpression;FunctionCallExpression;IdExpression;Name;IdExpression;Name;
-----ast_node-----
voidthread_lock_released(const void *lock, enum thread_lock_kind kind,	const void *element){	struct thread_element *te = deconstify_pointer(element);	struct thread_lock_stack *tls;	const struct thread_lock *l;	unsigned i;	/*	 * For the same reasons as in thread_lock_got(), lazily grab the thread	 * element.  Note that we may be in a situation where we did not get a	 * thread element at lock time but are able to get one now.	 */	if (NULL == te) {		te = thread_find(&te);	} else {		thread_element_check(te);	}	if G_UNLIKELY(NULL == te)		return;	tls = &te->locks;	if G_UNLIKELY(0 == tls->count) {		/*		 * Warn only if we have seen a lock once (te->stack_lock != NULL)		 * and when the stack is larger than the first lock acquired.		 *		 * Otherwise, it means that we're poping out from the place where		 * we first recorded a lock, and therefore it is obvious we cannot		 * have the lock recorded since we're before the call chain that		 * could record the first lock.		 */		if (			te->stack_lock != NULL &&			thread_stack_ptr_cmp(&te, te->stack_lock) >= 0		) {			s_minicarp("%s(): %s %p was not registered in thread #%u",				G_STRFUNC, thread_lock_kind_to_string(kind), lock, te->stid);		}		return;	}	/*	 * If lock is the top of the stack, we're done.	 */	l = &tls->arena[tls->count - 1];	if G_LIKELY(l->lock == lock) {		g_assert_log(l->kind == kind,			"%s(): %s %p is actually registered as %s in thread #%u",			G_STRFUNC, thread_lock_kind_to_string(kind), lock,			thread_lock_kind_to_string(l->kind), te->stid);		tls->count--;		/*		 * Handle signals if any are pending and can be delivered.		 */		if G_UNLIKELY(thread_sig_pending(te)) {			THREAD_STATS_INCX(sig_handled_while_unlocking);			thread_sig_handle(te);		}		/*		 * If the thread no longer holds any locks and it has to be suspended,		 * now is a good (and safe) time to do it.		 */		if G_UNLIKELY(te->suspend && 0 == tls->count)			thread_suspend_self(te);		return;	}	/*	 * Since the lock was not the one at the top of the stack, then it must be	 * absent in the whole stack, or we have an out-of-order lock release.	 */	if (tls->overflow)		return;				/* Stack overflowed, we're crashing */	for (i = 0; i < tls->count; i++) {		const struct thread_lock *ol = &tls->arena[i];		if (ol->lock == lock) {			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}	}}
void
thread_lock_released(const void *lock, enum thread_lock_kind kind,	const void *element)
thread_lock_released
const void *lock
const void
*lock
*
lock
enum thread_lock_kind kind
enum thread_lock_kind
thread_lock_kind
kind
kind
const void *element
const void
*element
*
element
{	struct thread_element *te = deconstify_pointer(element);	struct thread_lock_stack *tls;	const struct thread_lock *l;	unsigned i;	/*	 * For the same reasons as in thread_lock_got(), lazily grab the thread	 * element.  Note that we may be in a situation where we did not get a	 * thread element at lock time but are able to get one now.	 */	if (NULL == te) {		te = thread_find(&te);	} else {		thread_element_check(te);	}	if G_UNLIKELY(NULL == te)		return;	tls = &te->locks;	if G_UNLIKELY(0 == tls->count) {		/*		 * Warn only if we have seen a lock once (te->stack_lock != NULL)		 * and when the stack is larger than the first lock acquired.		 *		 * Otherwise, it means that we're poping out from the place where		 * we first recorded a lock, and therefore it is obvious we cannot		 * have the lock recorded since we're before the call chain that		 * could record the first lock.		 */		if (			te->stack_lock != NULL &&			thread_stack_ptr_cmp(&te, te->stack_lock) >= 0		) {			s_minicarp("%s(): %s %p was not registered in thread #%u",				G_STRFUNC, thread_lock_kind_to_string(kind), lock, te->stid);		}		return;	}	/*	 * If lock is the top of the stack, we're done.	 */	l = &tls->arena[tls->count - 1];	if G_LIKELY(l->lock == lock) {		g_assert_log(l->kind == kind,			"%s(): %s %p is actually registered as %s in thread #%u",			G_STRFUNC, thread_lock_kind_to_string(kind), lock,			thread_lock_kind_to_string(l->kind), te->stid);		tls->count--;		/*		 * Handle signals if any are pending and can be delivered.		 */		if G_UNLIKELY(thread_sig_pending(te)) {			THREAD_STATS_INCX(sig_handled_while_unlocking);			thread_sig_handle(te);		}		/*		 * If the thread no longer holds any locks and it has to be suspended,		 * now is a good (and safe) time to do it.		 */		if G_UNLIKELY(te->suspend && 0 == tls->count)			thread_suspend_self(te);		return;	}	/*	 * Since the lock was not the one at the top of the stack, then it must be	 * absent in the whole stack, or we have an out-of-order lock release.	 */	if (tls->overflow)		return;				/* Stack overflowed, we're crashing */	for (i = 0; i < tls->count; i++) {		const struct thread_lock *ol = &tls->arena[i];		if (ol->lock == lock) {			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}	}}
struct thread_element *te = deconstify_pointer(element);
struct thread_element *te = deconstify_pointer(element);
struct thread_element
thread_element
*te = deconstify_pointer(element)
*
te
= deconstify_pointer(element)
deconstify_pointer(element)
deconstify_pointer
deconstify_pointer
element
element
struct thread_lock_stack *tls;
struct thread_lock_stack *tls;
struct thread_lock_stack
thread_lock_stack
*tls
*
tls
const struct thread_lock *l;
const struct thread_lock *l;
const struct thread_lock
thread_lock
*l
*
l
unsigned i;
unsigned i;
unsigned
i
i
if (NULL == te) {		te = thread_find(&te);	} else {		thread_element_check(te);	}
NULL == te
NULL
NULL
te
te
{		te = thread_find(&te);	}
te = thread_find(&te);
te = thread_find(&te)
te
te
thread_find(&te)
thread_find
thread_find
&te
te
te
{		thread_element_check(te);	}
thread_element_check(te);
thread_element_check(te)
thread_element_check
thread_element_check
te
te
if G_UNLIKELY(NULL == te)		return;
tls = &te->locks;
tls = &te->locks
tls
tls
&te->locks
te->locks
te
te
locks
if G_UNLIKELY(0 == tls->count) {		/*		 * Warn only if we have seen a lock once (te->stack_lock != NULL)		 * and when the stack is larger than the first lock acquired.		 *		 * Otherwise, it means that we're poping out from the place where		 * we first recorded a lock, and therefore it is obvious we cannot		 * have the lock recorded since we're before the call chain that		 * could record the first lock.		 */		if (			te->stack_lock != NULL &&			thread_stack_ptr_cmp(&te, te->stack_lock) >= 0		) {			s_minicarp("%s(): %s %p was not registered in thread #%u",				G_STRFUNC, thread_lock_kind_to_string(kind), lock, te->stid);		}		return;	}
l = &tls->arena[tls->count - 1];
l = &tls->arena[tls->count - 1]
l
l
&tls->arena[tls->count - 1]
tls->arena[tls->count - 1]
tls->arena
tls
tls
arena
tls->count - 1
tls->count
tls
tls
count
1
if G_LIKELY(l->lock == lock) {		g_assert_log(l->kind == kind,			"%s(): %s %p is actually registered as %s in thread #%u",			G_STRFUNC, thread_lock_kind_to_string(kind), lock,			thread_lock_kind_to_string(l->kind), te->stid);		tls->count--;		/*		 * Handle signals if any are pending and can be delivered.		 */		if G_UNLIKELY(thread_sig_pending(te)) {			THREAD_STATS_INCX(sig_handled_while_unlocking);			thread_sig_handle(te);		}		/*		 * If the thread no longer holds any locks and it has to be suspended,		 * now is a good (and safe) time to do it.		 */		if G_UNLIKELY(te->suspend && 0 == tls->count)			thread_suspend_self(te);		return;	}
if (tls->overflow)		return;
tls->overflow
tls
tls
overflow
return;
for (i = 0; i < tls->count; i++) {		const struct thread_lock *ol = &tls->arena[i];		if (ol->lock == lock) {			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}	}
i = 0;
i = 0
i
i
0
i < tls->count
i
i
tls->count
tls
tls
count
i++
i
i
{		const struct thread_lock *ol = &tls->arena[i];		if (ol->lock == lock) {			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}	}
const struct thread_lock *ol = &tls->arena[i];
const struct thread_lock *ol = &tls->arena[i];
const struct thread_lock
thread_lock
*ol = &tls->arena[i]
*
ol
= &tls->arena[i]
&tls->arena[i]
tls->arena[i]
tls->arena
tls
tls
arena
i
i
if (ol->lock == lock) {			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}
ol->lock == lock
ol->lock
ol
ol
lock
lock
lock
{			tls->overflow = TRUE;	/* Avoid any overflow problems now */			s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);			thread_lock_dump(te);			/*			 * If crashing, it's interesting to learn about possible			 * out-of-order unlocking, because it may point to a true			 * bug in the crash handling, but let processing continue			 * to be able to dump useful information anyway.			 */			if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}		}
tls->overflow = TRUE;
tls->overflow = TRUE
tls->overflow
tls
tls
overflow
TRUE
TRUE
s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count);
s_rawwarn("%s releases %s %p at inner position %u/%zu",				thread_element_name(te), thread_lock_kind_to_string(kind),				lock, i + 1, tls->count)
s_rawwarn
s_rawwarn
"%s releases %s %p at inner position %u/%zu"
thread_element_name(te)
thread_element_name
thread_element_name
te
te
thread_lock_kind_to_string(kind)
thread_lock_kind_to_string
thread_lock_kind_to_string
kind
kind
lock
lock
i + 1
i
i
1
tls->count
tls
tls
count
thread_lock_dump(te);
thread_lock_dump(te)
thread_lock_dump
thread_lock_dump
te
te
if (				!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)			) {				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}
!thread_is_crashing() &&				0 == atomic_int_get(&thread_locks_disabled)
!thread_is_crashing()
thread_is_crashing()
thread_is_crashing
thread_is_crashing
0 == atomic_int_get(&thread_locks_disabled)
0
atomic_int_get(&thread_locks_disabled)
atomic_int_get
atomic_int_get
&thread_locks_disabled
thread_locks_disabled
thread_locks_disabled
{				s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));			}
s_error("out-of-order %s release",					thread_lock_kind_to_string(kind));
s_error("out-of-order %s release",					thread_lock_kind_to_string(kind))
s_error
s_error
"out-of-order %s release"
thread_lock_kind_to_string(kind)
thread_lock_kind_to_string
thread_lock_kind_to_string
kind
kind
-----joern-----
(52,120,0)
(85,61,0)
(5,0,0)
(8,112,0)
(100,42,0)
(158,105,0)
(163,167,0)
(39,129,0)
(70,22,0)
(3,54,0)
(79,151,0)
(65,109,0)
(18,140,0)
(47,121,0)
(143,37,0)
(156,10,0)
(112,109,0)
(147,79,0)
(60,114,0)
(144,132,0)
(136,26,0)
(27,41,0)
(148,107,0)
(132,140,0)
(145,38,0)
(125,47,0)
(116,54,0)
(10,156,0)
(80,109,0)
(77,25,0)
(132,144,0)
(63,114,0)
(72,99,0)
(129,39,0)
(160,95,0)
(47,144,0)
(1,124,0)
(133,16,0)
(20,77,0)
(93,158,0)
(139,85,0)
(29,54,0)
(151,79,0)
(98,167,0)
(21,58,0)
(109,120,0)
(128,35,0)
(22,55,0)
(12,30,0)
(26,136,0)
(96,123,0)
(13,129,0)
(32,126,0)
(25,77,0)
(168,25,0)
(113,77,0)
(69,71,0)
(39,0,0)
(165,8,0)
(122,20,0)
(37,77,0)
(2,107,0)
(58,169,0)
(34,90,0)
(139,97,0)
(131,47,0)
(92,153,0)
(166,55,0)
(1,31,0)
(19,137,0)
(26,91,0)
(159,129,0)
(50,137,0)
(26,121,0)
(20,82,0)
(66,54,0)
(26,110,0)
(124,54,0)
(83,62,0)
(142,147,0)
(84,60,0)
(153,87,0)
(61,85,0)
(40,11,0)
(140,54,0)
(123,42,0)
(38,126,0)
(89,59,0)
(126,38,0)
(77,121,0)
(57,167,0)
(8,41,0)
(78,49,0)
(23,28,0)
(47,87,0)
(77,16,0)
(75,151,0)
(153,140,0)
(46,39,0)
(6,26,0)
(98,3,0)
(84,146,0)
(33,65,0)
(169,11,0)
(90,34,0)
(117,132,0)
(161,61,0)
(87,153,0)
(48,151,0)
(67,65,0)
(4,37,0)
(169,58,0)
(164,26,0)
(43,26,0)
(104,136,0)
(62,16,0)
(28,64,0)
(65,30,0)
(1,162,0)
(1,40,0)
(107,106,0)
(42,123,0)
(102,138,0)
(76,0,0)
(141,130,0)
(37,0,0)
(154,0,0)
(77,37,0)
(68,54,0)
(101,54,0)
(42,100,0)
(112,8,0)
(35,54,0)
(22,115,0)
(55,22,0)
(118,132,0)
(24,96,0)
(47,138,0)
(87,82,0)
(155,156,0)
(119,106,0)
(151,75,0)
(88,38,0)
(134,5,0)
(74,139,0)
(9,110,0)
(44,49,0)
(127,105,0)
(103,25,0)
(110,26,0)
(157,47,0)
(61,60,0)
(123,96,0)
(51,138,0)
(30,65,0)
(114,60,0)
(7,84,0)
(108,158,0)
(10,106,0)
(149,87,0)
(17,99,0)
(45,153,0)
(109,112,0)
(114,56,0)
(71,11,0)
(79,49,0)
(105,16,0)
(81,34,0)
(85,139,0)
(75,126,0)
(111,77,0)
(150,110,0)
(96,90,0)
(90,96,0)
(152,3,0)
(95,82,0)
(47,95,0)
(162,35,0)
(59,64,0)
(106,10,0)
(86,54,0)
(77,20,0)
(11,54,0)
(99,60,0)
(140,18,0)
(136,82,0)
(73,60,0)
(106,107,0)
(135,156,0)
(94,41,0)
(18,10,0)
(55,82,0)
(130,77,0)
(36,58,0)
(167,98,0)
(41,8,0)
(30,121,0)
(49,79,0)
(126,75,0)
(53,120,0)
(14,54,0)
(87,47,0)
(47,11,0)
(79,147,0)
(77,130,0)
(3,98,0)
(95,47,0)
(138,47,0)
(144,47,0)
(8,0,0)
(10,18,0)
(15,140,0)
(64,11,0)
(60,54,0)
(154,137,1)
(33,109,1)
(157,87,1)
(46,0,1)
(77,20,1)
(126,38,1)
(44,78,1)
(112,8,1)
(42,100,1)
(47,144,1)
(156,135,1)
(5,0,1)
(87,153,1)
(12,65,1)
(87,82,1)
(111,20,1)
(125,157,1)
(27,94,1)
(78,147,1)
(149,153,1)
(2,156,1)
(136,104,1)
(37,0,1)
(47,138,1)
(168,37,1)
(79,49,1)
(75,151,1)
(62,83,1)
(80,39,1)
(79,147,1)
(119,107,1)
(22,55,1)
(37,4,1)
(67,33,1)
(89,28,1)
(60,114,1)
(158,93,1)
(148,2,1)
(135,155,1)
(25,103,1)
(20,82,1)
(26,136,1)
(93,108,1)
(85,61,1)
(45,140,1)
(1,31,1)
(65,67,1)
(41,27,1)
(70,123,1)
(169,58,1)
(84,60,1)
(8,165,1)
(8,41,1)
(165,41,1)
(71,69,1)
(132,140,1)
(134,123,1)
(113,105,1)
(105,127,1)
(24,42,1)
(76,154,1)
(13,46,1)
(88,145,1)
(138,51,1)
(161,74,1)
(144,132,1)
(61,161,1)
(7,99,1)
(155,15,1)
(63,73,1)
(90,34,1)
(159,13,1)
(30,12,1)
(17,60,1)
(136,82,1)
(10,106,1)
(1,39,1)
(77,121,1)
(39,0,1)
(3,98,1)
(1,162,1)
(129,159,1)
(100,62,1)
(118,131,1)
(47,95,1)
(18,10,1)
(123,96,1)
(162,75,1)
(30,121,1)
(28,23,1)
(61,60,1)
(21,47,1)
(47,121,1)
(77,130,1)
(134,22,1)
(81,24,1)
(92,45,1)
(75,126,1)
(166,70,1)
(84,7,1)
(26,110,1)
(0,76,1)
(69,59,1)
(106,119,1)
(130,141,1)
(48,79,1)
(106,107,1)
(30,65,1)
(160,125,1)
(139,85,1)
(34,81,1)
(51,102,1)
(137,50,1)
(153,140,1)
(141,113,1)
(103,168,1)
(94,80,1)
(151,48,1)
(5,134,1)
(104,164,1)
(46,5,1)
(123,42,1)
(10,156,1)
(162,26,1)
(164,6,1)
(95,82,1)
(108,30,1)
(102,144,1)
(131,95,1)
(58,36,1)
(26,121,1)
(114,56,1)
(55,166,1)
(147,142,1)
(74,99,1)
(49,44,1)
(98,167,1)
(109,112,1)
(39,129,1)
(96,90,1)
(32,38,1)
(95,160,1)
(55,82,1)
(143,111,1)
(77,37,1)
(47,87,1)
(72,17,1)
(117,118,1)
(31,137,1)
(57,163,1)
(4,143,1)
(150,9,1)
(122,130,1)
(107,148,1)
(65,109,1)
(99,72,1)
(142,126,1)
(77,25,1)
(50,19,1)
(124,84,1)
(1,40,1)
(127,158,1)
(132,117,1)
(151,79,1)
(140,18,1)
(38,88,1)
(126,32,1)
(36,21,1)
(167,57,1)
(134,30,1)
(59,89,1)
(6,75,1)
(23,169,1)
(9,43,1)
(163,152,1)
(153,92,1)
(110,150,1)
(124,139,1)
(43,136,1)
(114,63,1)
(20,122,1)
(99,60,1)
(87,149,1)
(145,3,1)
(83,77,1)
(8,0,1)
(1,124,1)
(40,71,1)
(87,153,2)
(151,79,2)
(39,137,2)
(1,124,2)
(109,112,2)
(130,30,2)
(75,151,2)
(79,49,2)
(18,10,2)
(151,126,2)
(61,99,2)
(104,75,2)
(113,30,2)
(7,99,2)
(81,42,2)
(22,55,2)
(46,39,2)
(159,39,2)
(96,42,2)
(47,138,2)
(153,140,2)
(65,39,2)
(77,25,2)
(3,98,2)
(34,42,2)
(31,137,2)
(114,56,2)
(8,41,2)
(159,137,2)
(98,167,2)
(41,39,2)
(93,30,2)
(77,37,2)
(47,95,2)
(79,126,2)
(5,0,2)
(123,96,2)
(26,136,2)
(83,30,2)
(99,60,2)
(110,75,2)
(70,123,2)
(90,42,2)
(80,39,2)
(42,30,2)
(164,75,2)
(142,126,2)
(67,39,2)
(62,30,2)
(25,30,2)
(129,137,2)
(6,75,2)
(60,114,2)
(103,30,2)
(46,137,2)
(49,126,2)
(77,121,2)
(134,39,2)
(30,121,2)
(12,39,2)
(108,30,2)
(140,18,2)
(61,60,2)
(55,82,2)
(39,0,2)
(169,58,2)
(76,137,2)
(10,156,2)
(139,85,2)
(24,42,2)
(112,8,2)
(47,121,2)
(136,82,2)
(13,137,2)
(8,0,2)
(9,75,2)
(74,99,2)
(1,31,2)
(85,61,2)
(111,30,2)
(37,30,2)
(150,75,2)
(106,107,2)
(85,99,2)
(55,123,2)
(37,0,2)
(48,126,2)
(96,90,2)
(122,30,2)
(158,30,2)
(30,65,2)
(10,106,2)
(123,30,2)
(161,99,2)
(166,123,2)
(22,123,2)
(139,99,2)
(77,20,2)
(1,162,2)
(90,34,2)
(30,39,2)
(39,129,2)
(126,38,2)
(143,30,2)
(84,60,2)
(141,30,2)
(8,39,2)
(5,39,2)
(144,132,2)
(13,39,2)
(77,130,2)
(87,82,2)
(100,30,2)
(123,42,2)
(44,126,2)
(109,39,2)
(47,87,2)
(168,30,2)
(94,39,2)
(39,39,2)
(1,40,2)
(75,126,2)
(77,30,2)
(65,109,2)
(78,126,2)
(147,126,2)
(26,121,2)
(79,147,2)
(165,39,2)
(136,75,2)
(20,30,2)
(20,82,2)
(84,99,2)
(33,39,2)
(129,39,2)
(26,75,2)
(132,140,2)
(47,144,2)
(0,137,2)
(43,75,2)
(105,30,2)
(154,137,2)
(26,110,2)
(112,39,2)
(42,100,2)
(4,30,2)
(95,82,2)
(127,30,2)
(27,39,2)
-----------------------------------
(0,i = 0)
(1,RET)
(2,tls)
(3,tls = &te->locks)
(4,1)
(5,i++)
(6,"%s()
(7,te)
(8,tls->arena[i])
(9,te)
(10,tls->arena[tls->count - 1])
(11,)
(12,lock)
(13,tls)
(14,l)
(15,l)
(16,)
(17,NULL)
(18,&tls->arena[tls->count - 1])
(19,tls)
(20,thread_lock_kind_to_string(kind)
(21,tls)
(22,s_error("out-of-order %s release",\n\\n\\t\\t\\t\\t\\tthread_lock_kind_to_string(kind)
(23,sig_handled_while_unlocking)
(24,0)
(25,tls->count)
(26,s_minicarp("%s()
(27,arena)
(28,THREAD_STATS_INCX(sig_handled_while_unlocking)
(29,for (i = 0; i < tls->count; i++)
(30,ol->lock == lock)
(31,return;)
(32,NULL)
(33,ol)
(34,&thread_locks_disabled)
(35,)
(36,count)
(37,i + 1)
(38,te->stack_lock)
(39,i < tls->count)
(40,return;)
(41,tls->arena)
(42,!thread_is_crashing()
(43,lock)
(44,stack_lock)
(45,l)
(46,i)
(47,g_assert_log(l->kind == kind,\n\\n\\t\\t\\t"%s()
(48,0)
(49,te->stack_lock)
(50,overflow)
(51,stid)
(52,ol)
(53,if (ol->lock == lock)
(54,)
(55,thread_lock_kind_to_string(kind)
(56,const void *element)
(57,locks)
(58,tls->count)
(59,thread_sig_handle(te)
(60,*te = deconstify_pointer(element)
(61,&te)
(62,thread_lock_dump(te)
(63,element)
(64,)
(65,ol->lock)
(66,i)
(67,lock)
(68,tls)
(69,te)
(70,"out-of-order %s release")
(71,thread_suspend_self(te)
(72,te)
(73,te)
(74,te)
(75,te->stack_lock != NULL &&\n\\n\\t\\t\\tthread_stack_ptr_cmp(&te, te->stack_lock)
(76,0)
(77,s_rawwarn("%s releases %s %p at inner position %u/%zu",\n\\n\\t\\t\\t\\tthread_element_name(te)
(78,te)
(79,thread_stack_ptr_cmp(&te, te->stack_lock)
(80,ol)
(81,thread_locks_disabled)
(82,enum thread_lock_kind kind)
(83,te)
(84,thread_element_check(te)
(85,thread_find(&te)
(86,if (tls->overflow)
(87,l->kind == kind)
(88,stack_lock)
(89,te)
(90,atomic_int_get(&thread_locks_disabled)
(91,)
(92,kind)
(93,overflow)
(94,tls)
(95,thread_lock_kind_to_string(kind)
(96,0 == atomic_int_get(&thread_locks_disabled)
(97,)
(98,&te->locks)
(99,NULL == te)
(100,thread_is_crashing()
(101,te)
(102,te)
(103,count)
(104,kind)
(105,tls->overflow = TRUE)
(106,tls->count - 1)
(107,tls->count)
(108,tls)
(109,*ol = &tls->arena[i])
(110,te->stid)
(111,lock)
(112,&tls->arena[i])
(113,"%s releases %s %p at inner position %u/%zu")
(114,deconstify_pointer(element)
(115,)
(116,if (NULL == te)
(117,kind)
(118,l)
(119,1)
(120,)
(121,const void *lock)
(122,kind)
(123,!thread_is_crashing()
(124,return;)
(125,G_STRFUNC)
(126,te->stack_lock != NULL)
(127,TRUE)
(128,if (\n\\n\\t\\t\\tte->stack_lock != NULL &&\n\\n\\t\\t\\tthread_stack_ptr_cmp(&te, te->stack_lock)
(129,tls->count)
(130,thread_element_name(te)
(131,lock)
(132,l->kind)
(133,if (\n\\n\\t\\t\\t\\t!thread_is_crashing()
(134,i)
(135,arena)
(136,thread_lock_kind_to_string(kind)
(137,tls->overflow)
(138,te->stid)
(139,te = thread_find(&te)
(140,l = &tls->arena[tls->count - 1])
(141,te)
(142,te)
(143,i)
(144,thread_lock_kind_to_string(l->kind)
(145,te)
(146,)
(147,&te)
(148,count)
(149,kind)
(150,stid)
(151,thread_stack_ptr_cmp(&te, te->stack_lock)
(152,tls)
(153,l->kind)
(154,i)
(155,tls)
(156,tls->arena)
(157,"%s()
(158,tls->overflow)
(159,count)
(160,kind)
(161,te)
(162,return;)
(163,te)
(164,G_STRFUNC)
(165,i)
(166,kind)
(167,te->locks)
(168,tls)
(169,tls->count--)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
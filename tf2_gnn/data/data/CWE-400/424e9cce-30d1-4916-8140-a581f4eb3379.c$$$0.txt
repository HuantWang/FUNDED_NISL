-----label-----
1
-----code-----
struct irq_affinity_desc *
irq_create_affinity_masks(unsigned int nvecs, struct irq_affinity *affd)
{
	unsigned int affvecs, curvec, usedvecs, i;
	struct irq_affinity_desc *masks = NULL;

	/*
	 * Determine the number of vectors which need interrupt affinities
	 * assigned. If the pre/post request exhausts the available vectors
	 * then nothing to do here except for invoking the calc_sets()
	 * callback so the device driver can adjust to the situation. If there
	 * is only a single vector, then managing the queue is pointless as
	 * well.
	 */
	if (nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)
		affvecs = nvecs - affd->pre_vectors - affd->post_vectors;
	else
		affvecs = 0;

	/*
	 * Simple invocations do not provide a calc_sets() callback. Install
	 * the generic one.
	 */
	if (!affd->calc_sets)
		affd->calc_sets = default_calc_sets;

	/* Recalculate the sets */
	affd->calc_sets(affd, affvecs);

	if (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))
		return NULL;

	/* Nothing to assign? */
	if (!affvecs)
		return NULL;

	masks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);
	if (!masks)
		return NULL;

	/* Fill out vectors at the beginning that don't need affinity */
	for (curvec = 0; curvec < affd->pre_vectors; curvec++)
		cpumask_copy(&masks[curvec].mask, irq_default_affinity);

	/*
	 * Spread on present CPUs starting from affd->pre_vectors. If we
	 * have multiple sets, build each sets affinity mask separately.
	 */
	for (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {
		unsigned int this_vecs = affd->set_size[i];
		int ret;

		ret = irq_build_affinity_masks(affd, curvec, this_vecs,
					       curvec, masks);
		if (ret) {
			kfree(masks);
			return NULL;
		}
		curvec += this_vecs;
		usedvecs += this_vecs;
	}

	/* Fill out vectors at the end that don't need affinity */
	if (usedvecs >= affvecs)
		curvec = affd->pre_vectors + affvecs;
	else
		curvec = affd->pre_vectors + usedvecs;
	for (; curvec < nvecs; curvec++)
		cpumask_copy(&masks[curvec].mask, irq_default_affinity);

	/* Mark the managed interrupts */
	for (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)
		masks[i].is_managed = 1;

	return masks;
}
-----children-----
1,2
1,3
1,4
2,3
4,5
4,6
4,7
4,8
7,8
7,9
9,10
11,12
11,13
12,13
14,15
14,16
17,18
17,19
17,20
17,21
17,22
17,23
17,24
17,25
17,26
17,27
17,28
17,29
17,30
17,31
17,32
18,19
19,20
19,21
19,22
19,23
19,24
21,22
23,24
25,26
27,28
29,30
30,31
30,32
31,32
33,34
33,35
33,36
36,37
37,38
39,40
39,41
39,42
40,41
40,42
41,42
41,43
42,43
45,46
45,47
46,47
48,49
48,50
49,50
49,51
50,51
53,54
53,55
54,55
57,58
58,59
58,60
59,60
61,62
61,63
62,63
62,64
63,64
65,66
65,67
66,67
69,70
69,71
70,71
73,74
74,75
74,76
75,76
78,79
78,80
79,80
80,81
80,82
81,82
84,85
85,86
85,87
86,87
86,88
87,88
90,91
92,93
93,94
93,95
93,96
94,95
94,96
95,96
98,99
100,101
102,103
102,104
103,104
103,105
104,105
106,107
106,108
107,108
107,109
108,109
111,112
113,114
114,115
116,117
116,118
117,118
118,119
120,121
121,122
123,124
124,125
124,126
125,126
127,128
127,129
127,130
127,131
128,129
130,131
132,133
133,134
134,135
135,136
137,138
139,140
139,141
140,141
141,142
143,144
144,145
146,147
146,148
146,149
146,150
147,148
148,149
148,150
149,150
152,153
152,154
153,154
155,156
155,157
156,157
159,160
160,161
162,163
163,164
163,165
163,166
164,165
166,167
167,168
167,169
168,169
168,170
169,170
171,172
174,175
176,177
176,178
176,179
176,180
177,178
178,179
178,180
179,180
179,181
180,181
183,184
183,185
184,185
187,188
187,189
188,189
190,191
190,192
191,192
194,195
195,196
197,198
197,199
197,200
197,201
197,202
197,203
198,199
199,200
199,201
201,202
201,203
203,204
204,205
204,206
205,206
205,207
206,207
209,210
211,212
212,213
212,214
214,215
216,217
217,218
217,219
218,219
220,221
220,222
220,223
220,224
220,225
220,226
221,222
223,224
225,226
227,228
229,230
231,232
233,234
233,235
234,235
236,237
236,238
237,238
238,239
238,240
239,240
241,242
243,244
244,245
246,247
247,248
247,249
248,249
250,251
252,253
253,254
253,255
254,255
256,257
258,259
258,260
258,261
259,260
259,261
260,261
262,263
264,265
265,266
265,267
266,267
268,269
268,270
269,270
269,271
270,271
273,274
275,276
276,277
276,278
277,278
279,280
279,281
280,281
280,282
281,282
284,285
286,287
286,288
286,289
286,290
288,289
288,290
289,290
291,292
293,294
294,295
296,297
297,298
297,299
297,300
298,299
300,301
301,302
301,303
302,303
302,304
303,304
305,306
308,309
310,311
310,312
310,313
310,314
311,312
312,313
312,314
313,314
315,316
315,317
316,317
319,320
319,321
320,321
322,323
322,324
323,324
325,326
325,327
326,327
329,330
330,331
332,333
333,334
333,335
334,335
334,336
335,336
335,337
336,337
338,339
342,343
343,344
-----nextToken-----
3,5,6,8,10,13,15,16,20,22,24,26,28,32,34,35,38,43,44,47,51,52,55,56,60,64,67,68,71,72,76,77,82,83,88,89,91,96,97,99,101,105,109,110,112,115,119,122,126,129,131,136,138,142,145,150,151,154,157,158,161,165,170,172,173,175,181,182,185,186,189,192,193,196,200,202,207,208,210,213,215,219,222,224,226,228,230,232,235,240,242,245,249,251,255,257,261,263,267,271,272,274,278,282,283,285,287,290,292,295,299,304,306,307,309,314,317,318,321,324,327,328,331,337,339,340,341,344
-----computeFrom-----
40,41
40,42
41,42
41,43
45,46
45,47
48,49
48,50
58,59
58,60
61,62
61,63
62,63
62,64
74,75
74,76
85,86
85,87
106,107
106,108
124,125
124,126
148,149
148,150
152,153
152,154
179,180
179,181
183,184
183,185
187,188
187,189
217,218
217,219
247,248
247,249
253,254
253,255
259,260
259,261
265,266
265,267
268,269
268,270
276,277
276,278
279,280
279,281
288,289
288,290
312,313
312,314
319,320
319,321
322,323
322,324
333,334
333,335
-----guardedBy-----
52,68
56,72
47,64
55,71
263,274
-----guardedByNegation-----
261,285
-----lastLexicalUse-----
-----jump-----
-----attribute-----
FunctionDefinition;ElaboratedTypeSpecifier;Name;FunctionDeclarator;Pointer;Name;ParameterDeclaration;SimpleDeclSpecifier;Declarator;Name;ParameterDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;SimpleDeclSpecifier;Declarator;Name;Declarator;Name;Declarator;Name;Declarator;Name;DeclarationStatement;SimpleDeclaration;ElaboratedTypeSpecifier;Name;Declarator;Pointer;Name;EqualsInitializer;IdExpression;Name;IfStatement;BinaryExpression;BinaryExpression;IdExpression;Name;LiteralExpression;BinaryExpression;IdExpression;Name;BinaryExpression;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;BinaryExpression;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;LiteralExpression;IfStatement;UnaryExpression;FieldReference;IdExpression;Name;Name;ExpressionStatement;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;FunctionCallExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;IdExpression;Name;IfStatement;FunctionCallExpression;IdExpression;Name;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ReturnStatement;IdExpression;Name;IfStatement;UnaryExpression;IdExpression;Name;ReturnStatement;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;FunctionCallExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;UnaryExpression;UnaryExpression;IdExpression;Name;IdExpression;Name;IfStatement;UnaryExpression;IdExpression;Name;ReturnStatement;IdExpression;Name;ForStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;LiteralExpression;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;UnaryExpression;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;UnaryExpression;FieldReference;ArraySubscriptExpression;IdExpression;Name;IdExpression;Name;Name;IdExpression;Name;ForStatement;ExpressionStatement;ExpressionList;BinaryExpression;IdExpression;Name;LiteralExpression;BinaryExpression;IdExpression;Name;LiteralExpression;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;UnaryExpression;IdExpression;Name;CompoundStatement;DeclarationStatement;SimpleDeclaration;SimpleDeclSpecifier;Declarator;Name;EqualsInitializer;ArraySubscriptExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;DeclarationStatement;SimpleDeclaration;SimpleDeclSpecifier;Declarator;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;FunctionCallExpression;IdExpression;Name;IdExpression;Name;IdExpression;Name;IdExpression;Name;IdExpression;Name;IdExpression;Name;IfStatement;IdExpression;Name;CompoundStatement;ExpressionStatement;FunctionCallExpression;IdExpression;Name;IdExpression;Name;ReturnStatement;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;IdExpression;Name;IfStatement;BinaryExpression;IdExpression;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ExpressionStatement;BinaryExpression;IdExpression;Name;BinaryExpression;FieldReference;IdExpression;Name;Name;IdExpression;Name;ForStatement;NullStatement;BinaryExpression;IdExpression;Name;IdExpression;Name;UnaryExpression;IdExpression;Name;ExpressionStatement;FunctionCallExpression;IdExpression;Name;UnaryExpression;FieldReference;ArraySubscriptExpression;IdExpression;Name;IdExpression;Name;Name;IdExpression;Name;ForStatement;ExpressionStatement;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;BinaryExpression;IdExpression;Name;BinaryExpression;IdExpression;Name;FieldReference;IdExpression;Name;Name;UnaryExpression;IdExpression;Name;ExpressionStatement;BinaryExpression;FieldReference;ArraySubscriptExpression;IdExpression;Name;IdExpression;Name;Name;LiteralExpression;ReturnStatement;IdExpression;Name;
-----ast_node-----
struct irq_affinity_desc *irq_create_affinity_masks(unsigned int nvecs, struct irq_affinity *affd){	unsigned int affvecs, curvec, usedvecs, i;	struct irq_affinity_desc *masks = NULL;	/*	 * Determine the number of vectors which need interrupt affinities	 * assigned. If the pre/post request exhausts the available vectors	 * then nothing to do here except for invoking the calc_sets()	 * callback so the device driver can adjust to the situation. If there	 * is only a single vector, then managing the queue is pointless as	 * well.	 */	if (nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)		affvecs = nvecs - affd->pre_vectors - affd->post_vectors;	else		affvecs = 0;	/*	 * Simple invocations do not provide a calc_sets() callback. Install	 * the generic one.	 */	if (!affd->calc_sets)		affd->calc_sets = default_calc_sets;	/* Recalculate the sets */	affd->calc_sets(affd, affvecs);	if (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))		return NULL;	/* Nothing to assign? */	if (!affvecs)		return NULL;	masks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);	if (!masks)		return NULL;	/* Fill out vectors at the beginning that don't need affinity */	for (curvec = 0; curvec < affd->pre_vectors; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);	/*	 * Spread on present CPUs starting from affd->pre_vectors. If we	 * have multiple sets, build each sets affinity mask separately.	 */	for (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {		unsigned int this_vecs = affd->set_size[i];		int ret;		ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks);		if (ret) {			kfree(masks);			return NULL;		}		curvec += this_vecs;		usedvecs += this_vecs;	}	/* Fill out vectors at the end that don't need affinity */	if (usedvecs >= affvecs)		curvec = affd->pre_vectors + affvecs;	else		curvec = affd->pre_vectors + usedvecs;	for (; curvec < nvecs; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);	/* Mark the managed interrupts */	for (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)		masks[i].is_managed = 1;	return masks;}
struct irq_affinity_desc
irq_affinity_desc
*irq_create_affinity_masks(unsigned int nvecs, struct irq_affinity *affd)
*
irq_create_affinity_masks
unsigned int nvecs
unsigned int
nvecs
nvecs
struct irq_affinity *affd
struct irq_affinity
irq_affinity
*affd
*
affd
{	unsigned int affvecs, curvec, usedvecs, i;	struct irq_affinity_desc *masks = NULL;	/*	 * Determine the number of vectors which need interrupt affinities	 * assigned. If the pre/post request exhausts the available vectors	 * then nothing to do here except for invoking the calc_sets()	 * callback so the device driver can adjust to the situation. If there	 * is only a single vector, then managing the queue is pointless as	 * well.	 */	if (nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)		affvecs = nvecs - affd->pre_vectors - affd->post_vectors;	else		affvecs = 0;	/*	 * Simple invocations do not provide a calc_sets() callback. Install	 * the generic one.	 */	if (!affd->calc_sets)		affd->calc_sets = default_calc_sets;	/* Recalculate the sets */	affd->calc_sets(affd, affvecs);	if (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))		return NULL;	/* Nothing to assign? */	if (!affvecs)		return NULL;	masks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);	if (!masks)		return NULL;	/* Fill out vectors at the beginning that don't need affinity */	for (curvec = 0; curvec < affd->pre_vectors; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);	/*	 * Spread on present CPUs starting from affd->pre_vectors. If we	 * have multiple sets, build each sets affinity mask separately.	 */	for (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {		unsigned int this_vecs = affd->set_size[i];		int ret;		ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks);		if (ret) {			kfree(masks);			return NULL;		}		curvec += this_vecs;		usedvecs += this_vecs;	}	/* Fill out vectors at the end that don't need affinity */	if (usedvecs >= affvecs)		curvec = affd->pre_vectors + affvecs;	else		curvec = affd->pre_vectors + usedvecs;	for (; curvec < nvecs; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);	/* Mark the managed interrupts */	for (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)		masks[i].is_managed = 1;	return masks;}
unsigned int affvecs, curvec, usedvecs, i;
unsigned int affvecs, curvec, usedvecs, i;
unsigned int
affvecs
affvecs
curvec
curvec
usedvecs
usedvecs
i
i
struct irq_affinity_desc *masks = NULL;
struct irq_affinity_desc *masks = NULL;
struct irq_affinity_desc
irq_affinity_desc
*masks = NULL
*
masks
= NULL
NULL
NULL
if (nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)		affvecs = nvecs - affd->pre_vectors - affd->post_vectors;	else		affvecs = 0;
nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors
nvecs > 1
nvecs
nvecs
1
nvecs > affd->pre_vectors + affd->post_vectors
nvecs
nvecs
affd->pre_vectors + affd->post_vectors
affd->pre_vectors
affd
affd
pre_vectors
affd->post_vectors
affd
affd
post_vectors
affvecs = nvecs - affd->pre_vectors - affd->post_vectors;
affvecs = nvecs - affd->pre_vectors - affd->post_vectors
affvecs
affvecs
nvecs - affd->pre_vectors - affd->post_vectors
nvecs - affd->pre_vectors
nvecs
nvecs
affd->pre_vectors
affd
affd
pre_vectors
affd->post_vectors
affd
affd
post_vectors
affvecs = 0;
affvecs = 0
affvecs
affvecs
0
if (!affd->calc_sets)		affd->calc_sets = default_calc_sets;
!affd->calc_sets
affd->calc_sets
affd
affd
calc_sets
affd->calc_sets = default_calc_sets;
affd->calc_sets = default_calc_sets
affd->calc_sets
affd
affd
calc_sets
default_calc_sets
default_calc_sets
affd->calc_sets(affd, affvecs);
affd->calc_sets(affd, affvecs)
affd->calc_sets
affd
affd
calc_sets
affd
affd
affvecs
affvecs
if (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))		return NULL;
WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS)
WARN_ON_ONCE
WARN_ON_ONCE
affd->nr_sets > IRQ_AFFINITY_MAX_SETS
affd->nr_sets
affd
affd
nr_sets
IRQ_AFFINITY_MAX_SETS
IRQ_AFFINITY_MAX_SETS
return NULL;
NULL
NULL
if (!affvecs)		return NULL;
!affvecs
affvecs
affvecs
return NULL;
NULL
NULL
masks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);
masks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL)
masks
masks
kcalloc(nvecs, sizeof(*masks), GFP_KERNEL)
kcalloc
kcalloc
nvecs
nvecs
sizeof(*masks)
(*masks)
*masks
masks
masks
GFP_KERNEL
GFP_KERNEL
if (!masks)		return NULL;
!masks
masks
masks
return NULL;
NULL
NULL
for (curvec = 0; curvec < affd->pre_vectors; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);
curvec = 0;
curvec = 0
curvec
curvec
0
curvec < affd->pre_vectors
curvec
curvec
affd->pre_vectors
affd
affd
pre_vectors
curvec++
curvec
curvec
cpumask_copy(&masks[curvec].mask, irq_default_affinity);
cpumask_copy(&masks[curvec].mask, irq_default_affinity)
cpumask_copy
cpumask_copy
&masks[curvec].mask
masks[curvec].mask
masks[curvec]
masks
masks
curvec
curvec
mask
irq_default_affinity
irq_default_affinity
for (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {		unsigned int this_vecs = affd->set_size[i];		int ret;		ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks);		if (ret) {			kfree(masks);			return NULL;		}		curvec += this_vecs;		usedvecs += this_vecs;	}
i = 0, usedvecs = 0;
i = 0, usedvecs = 0
i = 0
i
i
0
usedvecs = 0
usedvecs
usedvecs
0
i < affd->nr_sets
i
i
affd->nr_sets
affd
affd
nr_sets
i++
i
i
{		unsigned int this_vecs = affd->set_size[i];		int ret;		ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks);		if (ret) {			kfree(masks);			return NULL;		}		curvec += this_vecs;		usedvecs += this_vecs;	}
unsigned int this_vecs = affd->set_size[i];
unsigned int this_vecs = affd->set_size[i];
unsigned int
this_vecs = affd->set_size[i]
this_vecs
= affd->set_size[i]
affd->set_size[i]
affd->set_size
affd
affd
set_size
i
i
int ret;
int ret;
int
ret
ret
ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks);
ret = irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks)
ret
ret
irq_build_affinity_masks(affd, curvec, this_vecs,					       curvec, masks)
irq_build_affinity_masks
irq_build_affinity_masks
affd
affd
curvec
curvec
this_vecs
this_vecs
curvec
curvec
masks
masks
if (ret) {			kfree(masks);			return NULL;		}
ret
ret
{			kfree(masks);			return NULL;		}
kfree(masks);
kfree(masks)
kfree
kfree
masks
masks
return NULL;
NULL
NULL
curvec += this_vecs;
curvec += this_vecs
curvec
curvec
this_vecs
this_vecs
usedvecs += this_vecs;
usedvecs += this_vecs
usedvecs
usedvecs
this_vecs
this_vecs
if (usedvecs >= affvecs)		curvec = affd->pre_vectors + affvecs;	else		curvec = affd->pre_vectors + usedvecs;
usedvecs >= affvecs
usedvecs
usedvecs
affvecs
affvecs
curvec = affd->pre_vectors + affvecs;
curvec = affd->pre_vectors + affvecs
curvec
curvec
affd->pre_vectors + affvecs
affd->pre_vectors
affd
affd
pre_vectors
affvecs
affvecs
curvec = affd->pre_vectors + usedvecs;
curvec = affd->pre_vectors + usedvecs
curvec
curvec
affd->pre_vectors + usedvecs
affd->pre_vectors
affd
affd
pre_vectors
usedvecs
usedvecs
for (; curvec < nvecs; curvec++)		cpumask_copy(&masks[curvec].mask, irq_default_affinity);
;
curvec < nvecs
curvec
curvec
nvecs
nvecs
curvec++
curvec
curvec
cpumask_copy(&masks[curvec].mask, irq_default_affinity);
cpumask_copy(&masks[curvec].mask, irq_default_affinity)
cpumask_copy
cpumask_copy
&masks[curvec].mask
masks[curvec].mask
masks[curvec]
masks
masks
curvec
curvec
mask
irq_default_affinity
irq_default_affinity
for (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)		masks[i].is_managed = 1;
i = affd->pre_vectors;
i = affd->pre_vectors
i
i
affd->pre_vectors
affd
affd
pre_vectors
i < nvecs - affd->post_vectors
i
i
nvecs - affd->post_vectors
nvecs
nvecs
affd->post_vectors
affd
affd
post_vectors
i++
i
i
masks[i].is_managed = 1;
masks[i].is_managed = 1
masks[i].is_managed
masks[i]
masks
masks
i
i
is_managed
1
return masks;
masks
masks
-----joern-----
(91,98,0)
(167,25,0)
(14,186,0)
(142,182,0)
(149,156,0)
(196,69,0)
(106,37,0)
(128,133,0)
(189,131,0)
(42,143,0)
(51,3,0)
(150,186,0)
(99,144,0)
(124,69,0)
(76,3,0)
(79,48,0)
(97,21,0)
(79,47,0)
(68,68,0)
(123,20,0)
(22,5,0)
(11,168,0)
(192,186,0)
(22,105,0)
(42,86,0)
(136,47,0)
(100,132,0)
(37,106,0)
(29,13,0)
(6,197,0)
(98,182,0)
(144,161,0)
(155,86,0)
(80,123,0)
(145,176,0)
(187,186,0)
(19,168,0)
(116,48,0)
(135,152,0)
(107,131,0)
(37,161,0)
(71,43,0)
(72,90,0)
(79,146,0)
(153,160,0)
(120,22,0)
(1,161,0)
(133,171,0)
(29,21,0)
(131,16,0)
(87,165,0)
(105,45,0)
(25,45,0)
(149,163,0)
(20,123,0)
(144,90,0)
(71,166,0)
(119,143,0)
(160,13,0)
(174,37,0)
(62,166,0)
(95,157,0)
(32,18,0)
(106,75,0)
(51,51,0)
(7,152,0)
(35,78,0)
(149,78,0)
(171,133,0)
(84,147,0)
(193,13,0)
(197,5,0)
(59,78,0)
(180,54,0)
(51,75,0)
(55,186,0)
(179,45,0)
(110,186,0)
(1,152,0)
(108,176,0)
(8,75,0)
(184,79,0)
(61,186,0)
(37,8,0)
(58,1,0)
(94,37,0)
(123,161,0)
(65,43,0)
(165,160,0)
(31,3,0)
(191,98,0)
(5,197,0)
(13,172,0)
(21,29,0)
(44,78,0)
(71,147,0)
(163,149,0)
(152,135,0)
(146,79,0)
(151,186,0)
(100,9,0)
(8,29,0)
(2,157,0)
(37,68,0)
(158,123,0)
(168,149,0)
(44,156,0)
(76,156,0)
(49,156,0)
(56,186,0)
(105,22,0)
(195,105,0)
(105,48,0)
(38,18,0)
(3,172,0)
(190,61,0)
(121,116,0)
(178,76,0)
(135,161,0)
(109,135,0)
(54,180,0)
(10,31,0)
(185,3,0)
(41,98,0)
(41,125,0)
(166,98,0)
(9,161,0)
(19,47,0)
(76,51,0)
(39,37,0)
(28,124,0)
(157,18,0)
(85,132,0)
(152,1,0)
(138,75,0)
(129,95,0)
(82,89,0)
(42,2,0)
(96,42,0)
(175,3,0)
(37,48,0)
(177,29,0)
(139,7,0)
(114,79,0)
(46,159,0)
(101,163,0)
(5,22,0)
(23,146,0)
(81,48,0)
(200,45,0)
(69,45,0)
(131,143,0)
(119,100,0)
(117,157,0)
(152,7,0)
(146,54,0)
(31,47,0)
(68,8,0)
(173,68,0)
(156,119,0)
(115,106,0)
(76,78,0)
(122,186,0)
(149,168,0)
(66,119,0)
(199,135,0)
(51,8,0)
(171,118,0)
(34,186,0)
(30,11,0)
(183,53,0)
(108,159,0)
(18,161,0)
(9,100,0)
(61,78,0)
(16,131,0)
(130,144,0)
(176,108,0)
(83,186,0)
(81,125,0)
(165,161,0)
(169,48,0)
(79,168,0)
(194,165,0)
(133,157,0)
(164,186,0)
(89,31,0)
(29,8,0)
(124,161,0)
(33,61,0)
(71,56,0)
(88,192,0)
(170,86,0)
(64,1,0)
(111,133,0)
(50,68,0)
(102,186,0)
(93,168,0)
(61,156,0)
(70,11,0)
(68,45,0)
(92,41,0)
(188,89,0)
(98,161,0)
(11,47,0)
(90,144,0)
(48,159,0)
(56,48,0)
(7,143,0)
(31,51,0)
(0,163,0)
(162,51,0)
(163,161,0)
(43,98,0)
(18,157,0)
(148,81,0)
(69,124,0)
(132,100,0)
(67,192,0)
(71,41,0)
(86,161,0)
(4,149,0)
(21,161,0)
(15,186,0)
(126,186,0)
(61,161,0)
(12,2,0)
(104,8,0)
(147,98,0)
(11,143,0)
(16,7,0)
(160,165,0)
(140,21,0)
(17,75,0)
(119,156,0)
(141,180,0)
(24,118,0)
(127,90,0)
(31,89,0)
(113,56,0)
(86,42,0)
(73,76,0)
(26,132,0)
(90,127,0)
(112,13,0)
(57,171,0)
(47,31,0)
(198,37,0)
(132,161,0)
(52,9,0)
(60,159,0)
(154,124,0)
(159,108,0)
(100,119,0)
(176,192,0)
(103,9,0)
(63,44,0)
(181,186,0)
(27,37,0)
(74,105,0)
(89,161,0)
(68,75,0)
(137,19,0)
(7,16,0)
(36,75,0)
(54,146,0)
(48,186,0)
(133,48,0)
(159,48,0)
(53,13,0)
(2,42,0)
(134,186,0)
(77,51,0)
(159,143,0)
(37,45,0)
(149,78,1)
(195,69,1)
(149,4,1)
(95,129,1)
(163,101,1)
(87,153,1)
(8,29,1)
(6,5,1)
(25,45,1)
(180,141,1)
(196,45,1)
(119,100,1)
(146,23,1)
(176,145,1)
(135,161,1)
(180,54,1)
(31,3,1)
(79,47,1)
(19,168,1)
(114,11,1)
(200,116,1)
(78,59,1)
(12,95,1)
(44,156,1)
(13,112,1)
(117,11,1)
(109,199,1)
(163,161,1)
(130,99,1)
(54,146,1)
(165,161,1)
(88,67,1)
(182,142,1)
(92,81,1)
(193,69,1)
(197,6,1)
(166,62,1)
(11,70,1)
(183,51,1)
(167,197,1)
(154,28,1)
(139,131,1)
(112,193,1)
(153,3,1)
(38,32,1)
(175,185,1)
(70,30,1)
(159,60,1)
(106,37,1)
(37,68,1)
(96,12,1)
(76,51,1)
(162,77,1)
(140,104,1)
(37,94,1)
(45,179,1)
(135,109,1)
(141,54,1)
(29,177,1)
(170,96,1)
(31,10,1)
(108,176,1)
(89,161,1)
(153,53,1)
(166,98,1)
(98,161,1)
(133,128,1)
(71,166,1)
(64,135,1)
(144,161,1)
(79,168,1)
(40,106,1)
(197,5,1)
(97,140,1)
(63,127,1)
(95,157,1)
(59,35,1)
(37,45,1)
(11,47,1)
(30,168,1)
(51,8,1)
(189,192,1)
(111,2,1)
(18,161,1)
(160,165,1)
(84,127,1)
(159,143,1)
(91,20,1)
(37,48,1)
(156,119,1)
(155,170,1)
(68,8,1)
(21,161,1)
(52,103,1)
(32,117,1)
(174,198,1)
(7,152,1)
(79,184,1)
(147,84,1)
(71,41,1)
(116,121,1)
(39,115,1)
(31,51,1)
(26,85,1)
(29,21,1)
(81,48,1)
(81,148,1)
(50,173,1)
(1,161,1)
(190,20,1)
(90,144,1)
(171,133,1)
(146,79,1)
(68,45,1)
(22,120,1)
(82,136,1)
(66,49,1)
(72,144,1)
(133,48,1)
(123,161,1)
(188,82,1)
(159,108,1)
(128,111,1)
(198,27,1)
(105,45,1)
(107,189,1)
(56,48,1)
(173,40,1)
(90,72,1)
(53,183,1)
(178,73,1)
(30,19,1)
(179,200,1)
(43,65,1)
(120,105,1)
(127,90,1)
(19,47,1)
(68,50,1)
(5,22,1)
(1,58,1)
(2,157,1)
(33,190,1)
(80,78,1)
(76,156,1)
(71,147,1)
(61,78,1)
(77,68,1)
(131,143,1)
(104,160,1)
(194,87,1)
(16,131,1)
(51,3,1)
(115,8,1)
(46,169,1)
(119,143,1)
(30,47,1)
(19,137,1)
(51,51,1)
(93,76,1)
(68,68,1)
(18,38,1)
(98,191,1)
(9,52,1)
(80,156,1)
(176,192,1)
(118,24,1)
(20,123,1)
(152,1,1)
(124,154,1)
(11,168,1)
(191,91,1)
(74,195,1)
(42,143,1)
(24,171,1)
(49,16,1)
(41,98,1)
(137,180,1)
(29,13,1)
(60,108,1)
(152,135,1)
(149,163,1)
(142,98,1)
(28,196,1)
(76,3,1)
(116,48,1)
(105,48,1)
(157,18,1)
(71,56,1)
(123,158,1)
(23,79,1)
(73,160,1)
(61,161,1)
(171,57,1)
(44,63,1)
(190,182,1)
(100,9,1)
(169,44,1)
(2,42,1)
(57,133,1)
(41,92,1)
(16,7,1)
(131,107,1)
(27,39,1)
(31,89,1)
(69,124,1)
(192,88,1)
(12,157,1)
(132,26,1)
(37,8,1)
(129,118,1)
(11,143,1)
(101,0,1)
(196,25,1)
(86,161,1)
(136,76,1)
(148,40,1)
(76,78,1)
(0,93,1)
(94,174,1)
(79,48,1)
(3,175,1)
(132,161,1)
(86,155,1)
(165,194,1)
(69,45,1)
(100,132,1)
(42,86,1)
(105,74,1)
(168,149,1)
(44,78,1)
(48,159,1)
(65,44,1)
(51,162,1)
(61,156,1)
(158,80,1)
(85,9,1)
(76,178,1)
(113,2,1)
(62,116,1)
(121,48,1)
(185,13,1)
(160,13,1)
(35,16,1)
(177,21,1)
(21,97,1)
(184,114,1)
(71,43,1)
(124,161,1)
(47,31,1)
(22,105,1)
(56,113,1)
(144,130,1)
(61,33,1)
(37,161,1)
(147,98,1)
(9,161,1)
(99,61,1)
(43,98,1)
(4,163,1)
(25,167,1)
(199,139,1)
(53,13,1)
(7,143,1)
(58,64,1)
(149,156,1)
(10,89,1)
(133,157,1)
(103,66,1)
(89,188,1)
(145,46,1)
(28,69,2)
(35,16,2)
(180,11,2)
(70,11,2)
(96,2,2)
(31,3,2)
(98,20,2)
(2,160,2)
(22,69,2)
(95,2,2)
(28,116,2)
(132,161,2)
(149,78,2)
(71,166,2)
(185,116,2)
(159,108,2)
(128,2,2)
(198,160,2)
(13,116,2)
(119,100,2)
(171,2,2)
(42,143,2)
(25,45,2)
(153,116,2)
(51,51,2)
(0,76,2)
(37,8,2)
(11,160,2)
(132,16,2)
(51,3,2)
(142,20,2)
(124,69,2)
(12,2,2)
(31,89,2)
(114,11,2)
(31,51,2)
(10,76,2)
(20,123,2)
(38,160,2)
(178,160,2)
(196,69,2)
(86,160,2)
(167,69,2)
(168,149,2)
(66,16,2)
(53,40,2)
(16,131,2)
(176,44,2)
(171,133,2)
(89,76,2)
(100,9,2)
(37,161,2)
(21,160,2)
(92,40,2)
(11,11,2)
(61,161,2)
(131,143,2)
(146,79,2)
(18,161,2)
(87,40,2)
(177,160,2)
(42,2,2)
(119,16,2)
(124,161,2)
(97,160,2)
(135,161,2)
(159,44,2)
(76,51,2)
(106,37,2)
(105,48,2)
(146,11,2)
(52,16,2)
(68,40,2)
(170,160,2)
(100,16,2)
(86,161,2)
(74,69,2)
(89,161,2)
(170,2,2)
(30,11,2)
(61,78,2)
(139,131,2)
(68,45,2)
(27,160,2)
(79,47,2)
(159,143,2)
(76,160,2)
(86,2,2)
(127,90,2)
(79,11,2)
(124,116,2)
(19,168,2)
(197,69,2)
(165,116,2)
(175,116,2)
(2,2,2)
(8,160,2)
(29,13,2)
(144,161,2)
(37,68,2)
(69,124,2)
(105,45,2)
(71,41,2)
(165,161,2)
(51,40,2)
(105,69,2)
(85,16,2)
(81,48,2)
(44,156,2)
(7,143,2)
(48,44,2)
(30,160,2)
(155,160,2)
(71,147,2)
(24,2,2)
(156,16,2)
(70,160,2)
(165,40,2)
(94,160,2)
(50,40,2)
(166,98,2)
(147,98,2)
(141,11,2)
(44,127,2)
(78,16,2)
(39,160,2)
(188,76,2)
(16,7,2)
(41,98,2)
(168,76,2)
(51,8,2)
(71,43,2)
(56,48,2)
(4,76,2)
(176,192,2)
(68,68,2)
(147,127,2)
(194,40,2)
(3,116,2)
(76,78,2)
(22,105,2)
(145,44,2)
(69,69,2)
(196,116,2)
(6,69,2)
(160,165,2)
(182,20,2)
(26,16,2)
(163,161,2)
(61,156,2)
(111,2,2)
(184,11,2)
(106,160,2)
(42,86,2)
(129,2,2)
(160,13,2)
(120,69,2)
(157,160,2)
(112,116,2)
(133,48,2)
(123,161,2)
(21,161,2)
(32,160,2)
(19,11,2)
(40,160,2)
(152,131,2)
(56,160,2)
(42,160,2)
(197,5,2)
(115,160,2)
(79,168,2)
(5,69,2)
(155,2,2)
(5,22,2)
(49,16,2)
(63,127,2)
(108,176,2)
(148,40,2)
(191,20,2)
(91,20,2)
(79,48,2)
(154,69,2)
(29,21,2)
(183,40,2)
(54,11,2)
(194,116,2)
(73,160,2)
(57,2,2)
(95,157,2)
(149,163,2)
(156,119,2)
(41,40,2)
(103,16,2)
(11,143,2)
(29,160,2)
(113,160,2)
(199,131,2)
(69,116,2)
(160,116,2)
(7,131,2)
(101,76,2)
(154,116,2)
(18,160,2)
(121,44,2)
(31,76,2)
(2,157,2)
(9,161,2)
(12,160,2)
(90,144,2)
(77,40,2)
(153,40,2)
(200,116,2)
(98,161,2)
(69,45,2)
(46,44,2)
(76,156,2)
(137,11,2)
(54,146,2)
(37,160,2)
(47,76,2)
(174,160,2)
(82,76,2)
(71,56,2)
(43,98,2)
(7,152,2)
(11,168,2)
(37,48,2)
(8,29,2)
(163,76,2)
(68,8,2)
(59,16,2)
(195,69,2)
(117,160,2)
(47,31,2)
(23,11,2)
(133,157,2)
(65,44,2)
(108,44,2)
(1,161,2)
(1,131,2)
(109,131,2)
(135,131,2)
(140,160,2)
(162,40,2)
(58,131,2)
(160,40,2)
(45,116,2)
(149,76,2)
(169,44,2)
(136,76,2)
(96,160,2)
(48,159,2)
(157,18,2)
(62,116,2)
(173,40,2)
(9,16,2)
(116,44,2)
(11,47,2)
(152,135,2)
(93,76,2)
(118,2,2)
(193,116,2)
(84,127,2)
(116,48,2)
(87,116,2)
(37,45,2)
(100,132,2)
(133,2,2)
(152,1,2)
(60,44,2)
(166,116,2)
(2,42,2)
(25,69,2)
(76,3,2)
(43,44,2)
(64,131,2)
(104,160,2)
(81,40,2)
(53,13,2)
(44,78,2)
(119,143,2)
(19,47,2)
(149,156,2)
(179,116,2)
(180,54,2)
-----------------------------------
(0,affd)
(1,affd->post_vectors)
(2,i < nvecs - affd->post_vectors)
(3,usedvecs = 0)
(4,affvecs)
(5,&masks[curvec].mask)
(6,irq_default_affinity)
(7,nvecs > affd->pre_vectors + affd->post_vectors)
(8,this_vecs = affd->set_size[i])
(9,affd->pre_vectors)
(10,usedvecs)
(11,curvec < nvecs)
(12,i)
(13,i = 0)
(14,affvecs)
(15,if (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS)
(16,nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)
(17,if (ret)
(18,affd->pre_vectors)
(19,curvec++)
(20,!affd->calc_sets)
(21,affd->set_size)
(22,masks[curvec].mask)
(23,mask)
(24,1)
(25,curvec++)
(26,post_vectors)
(27,curvec)
(28,affd)
(29,affd->set_size[i])
(30,curvec)
(31,affd->pre_vectors + usedvecs)
(32,affd)
(33,affvecs)
(34,for (curvec = 0; curvec < affd->pre_vectors; curvec++)
(35,affvecs)
(36,ret)
(37,irq_build_affinity_masks(affd, curvec, this_vecs,\n\\n\\t\\t\\t\\t\\t       curvec, masks)
(38,pre_vectors)
(39,affd)
(40,ret)
(41,return NULL;)
(42,nvecs - affd->post_vectors)
(43,return NULL;)
(44,!affvecs)
(45,curvec = 0)
(46,nvecs)
(47,curvec = affd->pre_vectors + usedvecs)
(48,masks = kcalloc(nvecs, sizeof(*masks)
(49,affvecs)
(50,this_vecs)
(51,usedvecs += this_vecs)
(52,pre_vectors)
(53,i++)
(54,&masks[curvec].mask)
(55,usedvecs)
(56,return masks;)
(57,is_managed)
(58,post_vectors)
(59,0)
(60,GFP_KERNEL)
(61,affd->calc_sets(affd, affvecs)
(62,NULL)
(63,affvecs)
(64,affd)
(65,NULL)
(66,nvecs)
(67,masks)
(68,curvec += this_vecs)
(69,curvec < affd->pre_vectors)
(70,nvecs)
(71,RET)
(72,IRQ_AFFINITY_MAX_SETS)
(73,usedvecs)
(74,curvec)
(75,)
(76,usedvecs >= affvecs)
(77,usedvecs)
(78,affvecs = 0)
(79,masks[curvec])
(80,affd)
(81,kfree(masks)
(82,affd)
(83,if (nvecs > 1 && nvecs > affd->pre_vectors + affd->post_vectors)
(84,NULL)
(85,affd)
(86,affd->post_vectors)
(87,affd)
(88,NULL)
(89,affd->pre_vectors)
(90,affd->nr_sets > IRQ_AFFINITY_MAX_SETS)
(91,affd)
(92,NULL)
(93,curvec)
(94,masks)
(95,i++)
(96,nvecs)
(97,set_size)
(98,affd->calc_sets)
(99,affd)
(100,affd->pre_vectors - affd->post_vectors)
(101,pre_vectors)
(102,curvec)
(103,affd)
(104,this_vecs)
(105,masks[curvec])
(106,ret = irq_build_affinity_masks(affd, curvec, this_vecs,\n\\n\\t\\t\\t\\t\\t       curvec, masks)
(107,1)
(108,sizeof(*masks)
(109,pre_vectors)
(110,if (usedvecs >= affvecs)
(111,masks)
(112,0)
(113,masks)
(114,masks)
(115,ret)
(116,!masks)
(117,i)
(118,masks[i].is_managed = 1)
(119,nvecs - affd->pre_vectors - affd->post_vectors)
(120,mask)
(121,masks)
(122,for (i = 0, usedvecs = 0; i < affd->nr_sets; i++)
(123,affd->calc_sets)
(124,affd->pre_vectors)
(125,)
(126,if (!affd->calc_sets)
(127,WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS)
(128,i)
(129,i)
(130,nr_sets)
(131,nvecs > 1)
(132,affd->post_vectors)
(133,masks[i])
(134,i)
(135,affd->pre_vectors)
(136,curvec)
(137,curvec)
(138,this_vecs)
(139,nvecs)
(140,affd)
(141,irq_default_affinity)
(142,default_calc_sets)
(143,unsigned int nvecs)
(144,affd->nr_sets)
(145,masks)
(146,masks[curvec].mask)
(147,return NULL;)
(148,masks)
(149,affd->pre_vectors + affvecs)
(150,if (!affvecs)
(151,if (!masks)
(152,affd->pre_vectors + affd->post_vectors)
(153,i)
(154,pre_vectors)
(155,post_vectors)
(156,affvecs = nvecs - affd->pre_vectors - affd->post_vectors)
(157,i = affd->pre_vectors)
(158,calc_sets)
(159,kcalloc(nvecs, sizeof(*masks)
(160,i < affd->nr_sets)
(161,struct irq_affinity *affd)
(162,this_vecs)
(163,affd->pre_vectors)
(164,for (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)
(165,affd->nr_sets)
(166,return NULL;)
(167,curvec)
(168,curvec = affd->pre_vectors + affvecs)
(169,masks)
(170,affd)
(171,masks[i].is_managed)
(172,)
(173,curvec)
(174,curvec)
(175,0)
(176,*masks)
(177,i)
(178,affvecs)
(179,0)
(180,cpumask_copy(&masks[curvec].mask, irq_default_affinity)
(181,for (; curvec < nvecs; curvec++)
(182,affd->calc_sets = default_calc_sets)
(183,i)
(184,curvec)
(185,usedvecs)
(186,)
(187,masks)
(188,pre_vectors)
(189,nvecs)
(190,affd)
(191,calc_sets)
(192,*masks = NULL)
(193,i)
(194,nr_sets)
(195,masks)
(196,curvec)
(197,cpumask_copy(&masks[curvec].mask, irq_default_affinity)
(198,this_vecs)
(199,affd)
(200,curvec)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^